{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Qu\u2019est-ce qu\u2019un embedding ? Un embedding est une repr\u00e9sentation num\u00e9rique (vecteur) d\u2019un mot, d\u2019une phrase ou d\u2019un document dans un espace de dimension r\u00e9duite. Contrairement aux repr\u00e9sentations traditionnelles comme le one-hot encoding, les embeddings sont des vecteurs denses qui contiennent de l\u2019information s\u00e9mantique. Chaque mot est repr\u00e9sent\u00e9 par un vecteur de taille fixe (par exemple, 100 ou 300 dimensions), dans lequel chaque dimension encode un aspect abstrait du mot. L\u2019id\u00e9e principale est que des mots ayant un sens similaire auront des vecteurs proches dans l\u2019espace vectoriel. Les embeddings sont souvent appris automatiquement \u00e0 partir de grands corpus de texte, sans supervision directe. Ils permettent aux algorithmes de traitement du langage naturel de comprendre les relations s\u00e9mantiques et syntaxiques entre les mots.","title":"Principes de l'embedding"},{"location":"#quest-ce-quun-embedding","text":"Un embedding est une repr\u00e9sentation num\u00e9rique (vecteur) d\u2019un mot, d\u2019une phrase ou d\u2019un document dans un espace de dimension r\u00e9duite. Contrairement aux repr\u00e9sentations traditionnelles comme le one-hot encoding, les embeddings sont des vecteurs denses qui contiennent de l\u2019information s\u00e9mantique. Chaque mot est repr\u00e9sent\u00e9 par un vecteur de taille fixe (par exemple, 100 ou 300 dimensions), dans lequel chaque dimension encode un aspect abstrait du mot. L\u2019id\u00e9e principale est que des mots ayant un sens similaire auront des vecteurs proches dans l\u2019espace vectoriel. Les embeddings sont souvent appris automatiquement \u00e0 partir de grands corpus de texte, sans supervision directe. Ils permettent aux algorithmes de traitement du langage naturel de comprendre les relations s\u00e9mantiques et syntaxiques entre les mots.","title":"Qu\u2019est-ce qu\u2019un embedding ?"},{"location":"conclusion_technos/","text":"Architecture retenue L\u2019architecture globale de l\u2019application repose sur une approche coh\u00e9rente, hybride et orient\u00e9e performance , r\u00e9pondant \u00e0 la fois aux contraintes techniques du projet et aux exigences exprim\u00e9es par la cliente, notamment en mati\u00e8re de souverainet\u00e9 des donn\u00e9es et de p\u00e9rennit\u00e9 . Vue d\u2019ensemble L\u2019application est con\u00e7ue comme une application de bureau multiplateforme , reposant sur Tauri pour l\u2019encapsulation et l\u2019ex\u00e9cution locale, garantissant ainsi : un stockage et un traitement des donn\u00e9es en local , une faible empreinte m\u00e9moire et disque , des performances \u00e9lev\u00e9es , ind\u00e9pendantes d\u2019un moteur web embarqu\u00e9 lourd. \u00c0 l\u2019int\u00e9rieur de cette enveloppe desktop, l\u2019architecture front-end adopte une strat\u00e9gie en deux niveaux compl\u00e9mentaires : Front-End Astro Rendu HTML statique par d\u00e9faut ( content-first ) Routage et structuration globale de l\u2019application Chargement minimal de JavaScript Excellente accessibilit\u00e9 et lisibilit\u00e9 du code Maintenance facilit\u00e9e sur le long terme SolidJS (Astro Islands) Gestion des zones interactives cibl\u00e9es R\u00e9activit\u00e9 fine sans Virtual DOM Mise \u00e0 jour efficace des \u00e9tats locaux Interactions complexes (tableaux, formulaires, composants dynamiques) Cette combinaison permet de limiter strictement l\u2019interactivit\u00e9 aux zones n\u00e9cessaires , tout en conservant un rendu ultra-rapide et une exp\u00e9rience utilisateur fluide. Back-End Le back-end repose sur FastAPI , choisi pour : ses excellentes performances , la validation automatique des donn\u00e9es , la g\u00e9n\u00e9ration native de documentation interactive , sa modernit\u00e9 et son ad\u00e9quation avec des architectures \u00e9volutives. FastAPI assure la communication entre le front-end et la logique m\u00e9tier, tout en restant parfaitement int\u00e9gr\u00e9 \u00e0 un environnement local et s\u00e9curis\u00e9. B\u00e9n\u00e9fices globaux de l\u2019architecture Cette architecture nous permet de b\u00e9n\u00e9ficier du meilleur des diff\u00e9rents paradigmes : la rapidit\u00e9 et la fiabilit\u00e9 du statique avec Astro, la souplesse d\u2019un framework r\u00e9actif moderne avec SolidJS, la robustesse d\u2019un back-end Python moderne avec FastAPI, et la s\u00e9curit\u00e9 d\u2019une application de bureau l\u00e9g\u00e8re gr\u00e2ce \u00e0 Tauri. En synth\u00e8se, les choix technologiques op\u00e9r\u00e9s garantissent une application : performante d\u00e8s le premier rendu , respectueuse des contraintes de souverainet\u00e9 des donn\u00e9es , facile \u00e0 maintenir et \u00e0 faire \u00e9voluer , et offrant une exp\u00e9rience utilisateur moderne, fluide et ma\u00eetris\u00e9e . Cette architecture constitue ainsi une base solide, durable et adapt\u00e9e aux besoins actuels comme aux \u00e9volutions futures du projet. Sch\u00e9ma Au final, l'application peut \u00eatre repr\u00e9sent\u00e9e par ce sch\u00e9ma d'architecture","title":"Conclusion"},{"location":"conclusion_technos/#architecture-retenue","text":"L\u2019architecture globale de l\u2019application repose sur une approche coh\u00e9rente, hybride et orient\u00e9e performance , r\u00e9pondant \u00e0 la fois aux contraintes techniques du projet et aux exigences exprim\u00e9es par la cliente, notamment en mati\u00e8re de souverainet\u00e9 des donn\u00e9es et de p\u00e9rennit\u00e9 .","title":"Architecture retenue"},{"location":"conclusion_technos/#vue-densemble","text":"L\u2019application est con\u00e7ue comme une application de bureau multiplateforme , reposant sur Tauri pour l\u2019encapsulation et l\u2019ex\u00e9cution locale, garantissant ainsi : un stockage et un traitement des donn\u00e9es en local , une faible empreinte m\u00e9moire et disque , des performances \u00e9lev\u00e9es , ind\u00e9pendantes d\u2019un moteur web embarqu\u00e9 lourd. \u00c0 l\u2019int\u00e9rieur de cette enveloppe desktop, l\u2019architecture front-end adopte une strat\u00e9gie en deux niveaux compl\u00e9mentaires :","title":"Vue d\u2019ensemble"},{"location":"conclusion_technos/#front-end","text":"","title":"Front-End"},{"location":"conclusion_technos/#astro","text":"Rendu HTML statique par d\u00e9faut ( content-first ) Routage et structuration globale de l\u2019application Chargement minimal de JavaScript Excellente accessibilit\u00e9 et lisibilit\u00e9 du code Maintenance facilit\u00e9e sur le long terme","title":"Astro"},{"location":"conclusion_technos/#solidjs-astro-islands","text":"Gestion des zones interactives cibl\u00e9es R\u00e9activit\u00e9 fine sans Virtual DOM Mise \u00e0 jour efficace des \u00e9tats locaux Interactions complexes (tableaux, formulaires, composants dynamiques) Cette combinaison permet de limiter strictement l\u2019interactivit\u00e9 aux zones n\u00e9cessaires , tout en conservant un rendu ultra-rapide et une exp\u00e9rience utilisateur fluide.","title":"SolidJS (Astro Islands)"},{"location":"conclusion_technos/#back-end","text":"Le back-end repose sur FastAPI , choisi pour : ses excellentes performances , la validation automatique des donn\u00e9es , la g\u00e9n\u00e9ration native de documentation interactive , sa modernit\u00e9 et son ad\u00e9quation avec des architectures \u00e9volutives. FastAPI assure la communication entre le front-end et la logique m\u00e9tier, tout en restant parfaitement int\u00e9gr\u00e9 \u00e0 un environnement local et s\u00e9curis\u00e9.","title":"Back-End"},{"location":"conclusion_technos/#benefices-globaux-de-larchitecture","text":"Cette architecture nous permet de b\u00e9n\u00e9ficier du meilleur des diff\u00e9rents paradigmes : la rapidit\u00e9 et la fiabilit\u00e9 du statique avec Astro, la souplesse d\u2019un framework r\u00e9actif moderne avec SolidJS, la robustesse d\u2019un back-end Python moderne avec FastAPI, et la s\u00e9curit\u00e9 d\u2019une application de bureau l\u00e9g\u00e8re gr\u00e2ce \u00e0 Tauri. En synth\u00e8se, les choix technologiques op\u00e9r\u00e9s garantissent une application : performante d\u00e8s le premier rendu , respectueuse des contraintes de souverainet\u00e9 des donn\u00e9es , facile \u00e0 maintenir et \u00e0 faire \u00e9voluer , et offrant une exp\u00e9rience utilisateur moderne, fluide et ma\u00eetris\u00e9e . Cette architecture constitue ainsi une base solide, durable et adapt\u00e9e aux besoins actuels comme aux \u00e9volutions futures du projet.","title":"B\u00e9n\u00e9fices globaux de l\u2019architecture"},{"location":"conclusion_technos/#schema","text":"Au final, l'application peut \u00eatre repr\u00e9sent\u00e9e par ce sch\u00e9ma d'architecture","title":"Sch\u00e9ma"},{"location":"conclusions_personnelles/","text":"Noah J'ai trouv\u00e9 ce projet int\u00e9ressant, aussi bien du point de vue de la conception que des phases de recherche et de d\u00e9veloppement. Cette SAE nous a permis de d\u00e9couvrir et d'explorer de nouveaux aspects du d\u00e9veloppement informatique, notamment l'intelligence artificielle, un domaine que nous n'avons pas beaucoup abord\u00e9 en cours. Elle nous a \u00e9galement donn\u00e9 l'occasion de travailler avec des frameworks modernes, utiles et innovants tels que Tauri, Astro ou FastAPI , ce qui a \u00e9largi ma vision des outils actuellement utilis\u00e9s dans le monde professionnel. Cette SAE a aussi repr\u00e9sent\u00e9 une r\u00e9elle opportunit\u00e9 de progression personnelle. Elle m'a permis de renforcer mes comp\u00e9tences en d\u00e9veloppement web, en particulier en JavaScript, o\u00f9 je manquais de pratique et d'exp\u00e9rience. Le fait de devoir l'utiliser dans un contexte concret m'a aid\u00e9 \u00e0 mieux comprendre son fonctionnement et \u00e0 gagner en autonomie. Enfin, ce projet m'a appris \u00e0 mieux m'organiser avec une \u00e9quipe, \u00e0 rechercher des solutions par moi-m\u00eame et \u00e0 m'adapter \u00e0 de nouvelles technologies. Il a confirm\u00e9 mon int\u00e9r\u00eat pour le d\u00e9veloppement informatique et m'a donn\u00e9 envie d'approfondir davantage ces domaines \u00e0 l'avenir. Zacharie En tant que d\u00e9veloppeur, ce projet m'a permis de progresser dans plusieurs domaines dans lesquels je n'avais pas beaucoup d'exp\u00e9rience, comme la cr\u00e9ation de pipelines de d\u00e9ploiement continu, le d\u00e9veloppement d'applications de bureau, et \u00e9videmment l'IA. Le projet nous a aussi pouss\u00e9s \u00e0 mener des recherches pour choisir les technologies \u00e0 utiliser. Enfin, il m'a permis de m'am\u00e9liorer en travail d'\u00e9quipe, puisqu'il fallait coordonner les diff\u00e9rentes parties du d\u00e9veloppement. Malo Pour moi cette SAE fut sp\u00e9ciale pour plusieurs raisons, mais la principale \u00e9tant son contexte. En effet, contrairement aux pr\u00e9c\u00e9dentes SAE, nous avions un client avec des besoins et des exigences. Nous avons \u00e9galement r\u00e9ellement exp\u00e9riment\u00e9 le d\u00e9veloppement it\u00e9ratif, ce qui nous a permis de mettre en application de nombreux principes collaboratifs que jusqu'\u00e0 l\u00e0, nous n'avions vus uniquement sur le papier. Nous avons certes pris pas mal de fausses routes, mais ces erreurs nous ont permis de progresser et nous serviront d'exemples pour ne pas les reproduire en entreprise, c'est en cela que cette SAE se d\u00e9marque des pr\u00e9c\u00e9dentes. En plus de la progression technique, elle nous a \u00e9galement apport\u00e9 une grande exp\u00e9rience collaborative. Cependant, les comp\u00e9tences techniques ne sont pas en reste, utilisant de nombreuses technologies et demandant d'en essayer encore plus afin de choisir les plus pertinentes, le travail accompli apporte un bagage technique plus qu'utile afin de permettre des choix judicieux \u00e0 l'avenir. L'exemple de cela m'ayant le plus marqu\u00e9 personnellement \u00e9tant le choix de l'approche pour le parser, que ce soit pour choisir sa place dans l'architecture de l'application ou bien le dilemme sur la technologie utilis\u00e9e pour fonctionner Florian Personnellement, j'ai trouv\u00e9 beaucoup d'int\u00e9r\u00eat dans ce projet, et ce sous plusieurs aspects. Tout d'abord, la mise en situation et le sujet en eux-m\u00eames \u00e9taient assez pertinents : ils ont fourni un exercice complet, nous demandant de nous occuper du projet de A \u00e0 Z. De plus, le fait d'avoir un client avec qui dialoguer afin d'effectuer un recueil des besoins \u00e9tait tr\u00e8s instructif, notamment pour nous pousser \u00e0 sortir de notre zone de confort et \u00e0 utiliser des technologies plus r\u00e9centes ou que nous n'avions pas l'habitude d'employer. En outre, ce projet a \u00e9t\u00e9 une v\u00e9ritable aubaine en ce qui concerne le travail en \u00e9quipe. J'ai beaucoup appris sur la mani\u00e8re de se r\u00e9partir les t\u00e2ches, mais aussi sur la fa\u00e7on de communiquer efficacement avec les diff\u00e9rents membres du groupe. Pour conclure, ce projet m'a fait progresser sur de nombreux points, allant de ma ma\u00eetrise de l'informatique au travail en \u00e9quipe. M\u00eame si certains aspects ont pu \u00eatre d\u00e9licats \u00e0 appr\u00e9hender au premier abord, ces difficult\u00e9s ont rapidement \u00e9t\u00e9 surmont\u00e9es, donnant ainsi le projet tel qu'il est \u00e0 l'heure actuelle. Maxime Ce projet m\u2019a personnellement permis de d\u00e9couvrir des facettes du d\u00e9veloppement que je n\u2019avais encore jamais explor\u00e9es. Le fait de travailler sur des technologies et des frameworks modernes est tr\u00e8s formateur et permet de se pr\u00e9parer sur des technologies qui sont utilis\u00e9es dans des entreprises qui sont modernes et investies dans les technologies informatiques. En ce qui concerne l'organisation, la SAE m'a appris \u00e0 mieux g\u00e9rer mon temps et \u00e0 prioriser les t\u00e2ches en fonction des besoins actuels. Les retours r\u00e9guliers avec nos clients ont \u00e9t\u00e9 vraiment utiles et ont permis de ne pas s'\u00e9garer quand on avait une id\u00e9e biais\u00e9e de ce que voulait le client. Pour conclure, le projet est tr\u00e8s formateur sur beaucoup de points, notamment via les technologies qu'on utilise.","title":"Conclusions"},{"location":"conclusions_personnelles/#noah","text":"J'ai trouv\u00e9 ce projet int\u00e9ressant, aussi bien du point de vue de la conception que des phases de recherche et de d\u00e9veloppement. Cette SAE nous a permis de d\u00e9couvrir et d'explorer de nouveaux aspects du d\u00e9veloppement informatique, notamment l'intelligence artificielle, un domaine que nous n'avons pas beaucoup abord\u00e9 en cours. Elle nous a \u00e9galement donn\u00e9 l'occasion de travailler avec des frameworks modernes, utiles et innovants tels que Tauri, Astro ou FastAPI , ce qui a \u00e9largi ma vision des outils actuellement utilis\u00e9s dans le monde professionnel. Cette SAE a aussi repr\u00e9sent\u00e9 une r\u00e9elle opportunit\u00e9 de progression personnelle. Elle m'a permis de renforcer mes comp\u00e9tences en d\u00e9veloppement web, en particulier en JavaScript, o\u00f9 je manquais de pratique et d'exp\u00e9rience. Le fait de devoir l'utiliser dans un contexte concret m'a aid\u00e9 \u00e0 mieux comprendre son fonctionnement et \u00e0 gagner en autonomie. Enfin, ce projet m'a appris \u00e0 mieux m'organiser avec une \u00e9quipe, \u00e0 rechercher des solutions par moi-m\u00eame et \u00e0 m'adapter \u00e0 de nouvelles technologies. Il a confirm\u00e9 mon int\u00e9r\u00eat pour le d\u00e9veloppement informatique et m'a donn\u00e9 envie d'approfondir davantage ces domaines \u00e0 l'avenir.","title":"Noah"},{"location":"conclusions_personnelles/#zacharie","text":"En tant que d\u00e9veloppeur, ce projet m'a permis de progresser dans plusieurs domaines dans lesquels je n'avais pas beaucoup d'exp\u00e9rience, comme la cr\u00e9ation de pipelines de d\u00e9ploiement continu, le d\u00e9veloppement d'applications de bureau, et \u00e9videmment l'IA. Le projet nous a aussi pouss\u00e9s \u00e0 mener des recherches pour choisir les technologies \u00e0 utiliser. Enfin, il m'a permis de m'am\u00e9liorer en travail d'\u00e9quipe, puisqu'il fallait coordonner les diff\u00e9rentes parties du d\u00e9veloppement.","title":"Zacharie"},{"location":"conclusions_personnelles/#malo","text":"Pour moi cette SAE fut sp\u00e9ciale pour plusieurs raisons, mais la principale \u00e9tant son contexte. En effet, contrairement aux pr\u00e9c\u00e9dentes SAE, nous avions un client avec des besoins et des exigences. Nous avons \u00e9galement r\u00e9ellement exp\u00e9riment\u00e9 le d\u00e9veloppement it\u00e9ratif, ce qui nous a permis de mettre en application de nombreux principes collaboratifs que jusqu'\u00e0 l\u00e0, nous n'avions vus uniquement sur le papier. Nous avons certes pris pas mal de fausses routes, mais ces erreurs nous ont permis de progresser et nous serviront d'exemples pour ne pas les reproduire en entreprise, c'est en cela que cette SAE se d\u00e9marque des pr\u00e9c\u00e9dentes. En plus de la progression technique, elle nous a \u00e9galement apport\u00e9 une grande exp\u00e9rience collaborative. Cependant, les comp\u00e9tences techniques ne sont pas en reste, utilisant de nombreuses technologies et demandant d'en essayer encore plus afin de choisir les plus pertinentes, le travail accompli apporte un bagage technique plus qu'utile afin de permettre des choix judicieux \u00e0 l'avenir. L'exemple de cela m'ayant le plus marqu\u00e9 personnellement \u00e9tant le choix de l'approche pour le parser, que ce soit pour choisir sa place dans l'architecture de l'application ou bien le dilemme sur la technologie utilis\u00e9e pour fonctionner","title":"Malo"},{"location":"conclusions_personnelles/#florian","text":"Personnellement, j'ai trouv\u00e9 beaucoup d'int\u00e9r\u00eat dans ce projet, et ce sous plusieurs aspects. Tout d'abord, la mise en situation et le sujet en eux-m\u00eames \u00e9taient assez pertinents : ils ont fourni un exercice complet, nous demandant de nous occuper du projet de A \u00e0 Z. De plus, le fait d'avoir un client avec qui dialoguer afin d'effectuer un recueil des besoins \u00e9tait tr\u00e8s instructif, notamment pour nous pousser \u00e0 sortir de notre zone de confort et \u00e0 utiliser des technologies plus r\u00e9centes ou que nous n'avions pas l'habitude d'employer. En outre, ce projet a \u00e9t\u00e9 une v\u00e9ritable aubaine en ce qui concerne le travail en \u00e9quipe. J'ai beaucoup appris sur la mani\u00e8re de se r\u00e9partir les t\u00e2ches, mais aussi sur la fa\u00e7on de communiquer efficacement avec les diff\u00e9rents membres du groupe. Pour conclure, ce projet m'a fait progresser sur de nombreux points, allant de ma ma\u00eetrise de l'informatique au travail en \u00e9quipe. M\u00eame si certains aspects ont pu \u00eatre d\u00e9licats \u00e0 appr\u00e9hender au premier abord, ces difficult\u00e9s ont rapidement \u00e9t\u00e9 surmont\u00e9es, donnant ainsi le projet tel qu'il est \u00e0 l'heure actuelle.","title":"Florian"},{"location":"conclusions_personnelles/#maxime","text":"Ce projet m\u2019a personnellement permis de d\u00e9couvrir des facettes du d\u00e9veloppement que je n\u2019avais encore jamais explor\u00e9es. Le fait de travailler sur des technologies et des frameworks modernes est tr\u00e8s formateur et permet de se pr\u00e9parer sur des technologies qui sont utilis\u00e9es dans des entreprises qui sont modernes et investies dans les technologies informatiques. En ce qui concerne l'organisation, la SAE m'a appris \u00e0 mieux g\u00e9rer mon temps et \u00e0 prioriser les t\u00e2ches en fonction des besoins actuels. Les retours r\u00e9guliers avec nos clients ont \u00e9t\u00e9 vraiment utiles et ont permis de ne pas s'\u00e9garer quand on avait une id\u00e9e biais\u00e9e de ce que voulait le client. Pour conclure, le projet est tr\u00e8s formateur sur beaucoup de points, notamment via les technologies qu'on utilise.","title":"Maxime"},{"location":"contexte_technos/","text":"Notre d\u00e9marche Format Nous avions initialement envisag\u00e9 le d\u00e9veloppement d\u2019une application web h\u00e9berg\u00e9e sur un serveur , afin de garantir une accessibilit\u00e9 simple et universelle depuis n\u2019importe quel terminal. Ce choix facilitait \u00e9galement la maintenance et les mises \u00e0 jour de l\u2019application. Cependant, lors des \u00e9changes avec notre cliente, des pr\u00e9occupations li\u00e9es \u00e0 la souverainet\u00e9 des donn\u00e9es ont \u00e9t\u00e9 soulev\u00e9es. L\u2019h\u00e9bergement distant des donn\u00e9es ne r\u00e9pondait pas pleinement aux exigences de s\u00e9curit\u00e9 et de ma\u00eetrise des informations. Nous avons donc orient\u00e9 notre r\u00e9flexion vers une application de bureau , permettant un traitement et un stockage des donn\u00e9es en local . Dans ce contexte, nous avons \u00e9tudi\u00e9 plusieurs technologies permettant de transformer une application en solution de bureau multiplateforme. Trois frameworks se sont d\u00e9marqu\u00e9s : Flet , un framework Python bas\u00e9 sur Flutter, Electron , une solution JavaScript largement utilis\u00e9e, et Tauri , un framework r\u00e9cent reposant sur Rust. Notre choix s\u2019est port\u00e9 sur Tauri , principalement en raison de sa l\u00e9g\u00e8ret\u00e9 , de ses bonnes performances et de sa faible consommation de ressources . Contrairement \u00e0 Electron, qui embarque un moteur Chromium complet, Tauri s\u2019appuie sur le moteur web natif du syst\u00e8me, ce qui permet de produire des applications plus rapides et plus compactes. Tableau comparatif des technologies \u00e9tudi\u00e9es Crit\u00e8re Flet Electron Tauri Langage principal Python JavaScript / TypeScript Rust (backend) + Web Poids de l\u2019application Moyen \u00c9lev\u00e9 Tr\u00e8s faible Consommation m\u00e9moire Moyenne \u00c9lev\u00e9e Faible Performances Bonnes Correctes Excellentes S\u00e9curit\u00e9 Standard Standard \u00c9lev\u00e9e Front-End Dans le cadre du d\u00e9veloppement du front-end de l\u2019application, notre \u00e9quipe a pris le temps d\u2019\u00e9valuer plusieurs frameworks modernes tels que React, Vue, Svelte, Solid, Astro, Next.js , ainsi que d\u2019autres solutions \u00e9mergentes. Cette phase d\u2019\u00e9tude avait pour objectif d\u2019identifier la technologie la plus adapt\u00e9e \u00e0 nos contraintes fonctionnelles et techniques. Nous recherchions une solution capable de concilier performance , simplicit\u00e9 de mise en \u0153uvre , \u00e9volutivit\u00e9 et interactivit\u00e9 , tout en restant coh\u00e9rente avec la nature du projet : une application l\u00e9g\u00e8re, rapide \u00e0 charger et facile \u00e0 maintenir sur le long terme . \u00c0 l\u2019issue de cette comparaison, nous avons d\u00e9cid\u00e9 d\u2019adopter Astro comme framework principal pour le rendu et la structure globale, accompagn\u00e9 de SolidJS pour g\u00e9rer les parties interactives via le syst\u00e8me des Astro Islands . Back-End Concernant le back-end de l\u2019application, l\u2019un de nos pr\u00e9requis majeurs \u00e9tait l\u2019utilisation du langage Python . Nous avons donc \u00e9valu\u00e9 plusieurs frameworks Python capables d\u2019assurer la communication entre le front-end et la logique m\u00e9tier de l\u2019application. Dans un premier temps, notre attention s\u2019est port\u00e9e sur Flask , un framework web l\u00e9ger, rapide \u00e0 mettre en \u0153uvre et tr\u00e8s simple d\u2019utilisation . Flask est particuli\u00e8rement adapt\u00e9 aux projets de petite \u00e0 moyenne envergure et offre une grande flexibilit\u00e9 gr\u00e2ce \u00e0 son approche minimaliste. Apr\u00e8s pr\u00e9sentation de cette solution \u00e0 notre cliente. Elle nous a partag\u00e9 qu'elle consid\u00e9rait Flask comme un framework relativement ancien , n\u00e9cessitant de nombreux modules additionnels pour r\u00e9pondre \u00e0 des besoins modernes (validation des donn\u00e9es, documentation automatique, performances \u00e9lev\u00e9es). Suite aux recommandations d\u2019une de ses connaissances, elle nous a sugg\u00e9r\u00e9 d\u2019envisager l\u2019utilisation de FastAPI . Nous nous sommes donc orient\u00e9s vers FastAPI , un framework Python moderne con\u00e7u pour le d\u00e9veloppement d\u2019 API rapides et performantes . FastAPI permet une validation automatique des donn\u00e9es , une documentation interactive g\u00e9n\u00e9r\u00e9e automatiquement et d\u2019excellentes performances, proches de celles de frameworks plus bas niveau. Ces caract\u00e9ristiques en font une solution particuli\u00e8rement adapt\u00e9e \u00e0 notre projet et aux attentes de notre cliente.","title":"Introduction"},{"location":"contexte_technos/#notre-demarche","text":"","title":"Notre d\u00e9marche"},{"location":"contexte_technos/#format","text":"Nous avions initialement envisag\u00e9 le d\u00e9veloppement d\u2019une application web h\u00e9berg\u00e9e sur un serveur , afin de garantir une accessibilit\u00e9 simple et universelle depuis n\u2019importe quel terminal. Ce choix facilitait \u00e9galement la maintenance et les mises \u00e0 jour de l\u2019application. Cependant, lors des \u00e9changes avec notre cliente, des pr\u00e9occupations li\u00e9es \u00e0 la souverainet\u00e9 des donn\u00e9es ont \u00e9t\u00e9 soulev\u00e9es. L\u2019h\u00e9bergement distant des donn\u00e9es ne r\u00e9pondait pas pleinement aux exigences de s\u00e9curit\u00e9 et de ma\u00eetrise des informations. Nous avons donc orient\u00e9 notre r\u00e9flexion vers une application de bureau , permettant un traitement et un stockage des donn\u00e9es en local . Dans ce contexte, nous avons \u00e9tudi\u00e9 plusieurs technologies permettant de transformer une application en solution de bureau multiplateforme. Trois frameworks se sont d\u00e9marqu\u00e9s : Flet , un framework Python bas\u00e9 sur Flutter, Electron , une solution JavaScript largement utilis\u00e9e, et Tauri , un framework r\u00e9cent reposant sur Rust. Notre choix s\u2019est port\u00e9 sur Tauri , principalement en raison de sa l\u00e9g\u00e8ret\u00e9 , de ses bonnes performances et de sa faible consommation de ressources . Contrairement \u00e0 Electron, qui embarque un moteur Chromium complet, Tauri s\u2019appuie sur le moteur web natif du syst\u00e8me, ce qui permet de produire des applications plus rapides et plus compactes.","title":"Format"},{"location":"contexte_technos/#tableau-comparatif-des-technologies-etudiees","text":"Crit\u00e8re Flet Electron Tauri Langage principal Python JavaScript / TypeScript Rust (backend) + Web Poids de l\u2019application Moyen \u00c9lev\u00e9 Tr\u00e8s faible Consommation m\u00e9moire Moyenne \u00c9lev\u00e9e Faible Performances Bonnes Correctes Excellentes S\u00e9curit\u00e9 Standard Standard \u00c9lev\u00e9e","title":"Tableau comparatif des technologies \u00e9tudi\u00e9es"},{"location":"contexte_technos/#front-end","text":"Dans le cadre du d\u00e9veloppement du front-end de l\u2019application, notre \u00e9quipe a pris le temps d\u2019\u00e9valuer plusieurs frameworks modernes tels que React, Vue, Svelte, Solid, Astro, Next.js , ainsi que d\u2019autres solutions \u00e9mergentes. Cette phase d\u2019\u00e9tude avait pour objectif d\u2019identifier la technologie la plus adapt\u00e9e \u00e0 nos contraintes fonctionnelles et techniques. Nous recherchions une solution capable de concilier performance , simplicit\u00e9 de mise en \u0153uvre , \u00e9volutivit\u00e9 et interactivit\u00e9 , tout en restant coh\u00e9rente avec la nature du projet : une application l\u00e9g\u00e8re, rapide \u00e0 charger et facile \u00e0 maintenir sur le long terme . \u00c0 l\u2019issue de cette comparaison, nous avons d\u00e9cid\u00e9 d\u2019adopter Astro comme framework principal pour le rendu et la structure globale, accompagn\u00e9 de SolidJS pour g\u00e9rer les parties interactives via le syst\u00e8me des Astro Islands .","title":"Front-End"},{"location":"contexte_technos/#back-end","text":"Concernant le back-end de l\u2019application, l\u2019un de nos pr\u00e9requis majeurs \u00e9tait l\u2019utilisation du langage Python . Nous avons donc \u00e9valu\u00e9 plusieurs frameworks Python capables d\u2019assurer la communication entre le front-end et la logique m\u00e9tier de l\u2019application. Dans un premier temps, notre attention s\u2019est port\u00e9e sur Flask , un framework web l\u00e9ger, rapide \u00e0 mettre en \u0153uvre et tr\u00e8s simple d\u2019utilisation . Flask est particuli\u00e8rement adapt\u00e9 aux projets de petite \u00e0 moyenne envergure et offre une grande flexibilit\u00e9 gr\u00e2ce \u00e0 son approche minimaliste. Apr\u00e8s pr\u00e9sentation de cette solution \u00e0 notre cliente. Elle nous a partag\u00e9 qu'elle consid\u00e9rait Flask comme un framework relativement ancien , n\u00e9cessitant de nombreux modules additionnels pour r\u00e9pondre \u00e0 des besoins modernes (validation des donn\u00e9es, documentation automatique, performances \u00e9lev\u00e9es). Suite aux recommandations d\u2019une de ses connaissances, elle nous a sugg\u00e9r\u00e9 d\u2019envisager l\u2019utilisation de FastAPI . Nous nous sommes donc orient\u00e9s vers FastAPI , un framework Python moderne con\u00e7u pour le d\u00e9veloppement d\u2019 API rapides et performantes . FastAPI permet une validation automatique des donn\u00e9es , une documentation interactive g\u00e9n\u00e9r\u00e9e automatiquement et d\u2019excellentes performances, proches de celles de frameworks plus bas niveau. Ces caract\u00e9ristiques en font une solution particuli\u00e8rement adapt\u00e9e \u00e0 notre projet et aux attentes de notre cliente.","title":"Back-End"},{"location":"contextualized/","text":"Embeddings contextualis\u00e9s (Contextualized Word Embeddings) Ces embeddings tiennent compte du contexte dans lequel le mot appara\u00eet. Le m\u00eame mot peut donc avoir plusieurs repr\u00e9sentations diff\u00e9rentes selon la phrase (ex : \u201cbark\u201d en anglais peut d\u00e9signer un aboiement ou une \u00e9corce). Utilisent des architectures avanc\u00e9es comme les r\u00e9seaux LSTM bidirectionnels ou les Transformers. Exemples ELMo : produit un vecteur pour chaque mot en tenant compte de toute la phrase, via des LSTM bidirectionnels. BERT : mod\u00e8le bas\u00e9 sur les Transformers ; produit des vecteurs contextuels riches pour chaque mot. GPT, RoBERTa, XLNet, etc. : d\u2019autres variantes de mod\u00e8les pr\u00e9entra\u00een\u00e9s de type Transformer. Avantages tr\u00e8s performants, capturent le sens r\u00e9el du mot dans son contexte. Inconv\u00e9nients lourds \u00e0 entra\u00eener et \u00e0 d\u00e9ployer, difficilement interpr\u00e9tables.","title":"Contextualized Word Embeddings"},{"location":"contextualized/#embeddings-contextualises-contextualized-word-embeddings","text":"Ces embeddings tiennent compte du contexte dans lequel le mot appara\u00eet. Le m\u00eame mot peut donc avoir plusieurs repr\u00e9sentations diff\u00e9rentes selon la phrase (ex : \u201cbark\u201d en anglais peut d\u00e9signer un aboiement ou une \u00e9corce). Utilisent des architectures avanc\u00e9es comme les r\u00e9seaux LSTM bidirectionnels ou les Transformers.","title":"Embeddings contextualis\u00e9s (Contextualized Word Embeddings)"},{"location":"contextualized/#exemples","text":"ELMo : produit un vecteur pour chaque mot en tenant compte de toute la phrase, via des LSTM bidirectionnels. BERT : mod\u00e8le bas\u00e9 sur les Transformers ; produit des vecteurs contextuels riches pour chaque mot. GPT, RoBERTa, XLNet, etc. : d\u2019autres variantes de mod\u00e8les pr\u00e9entra\u00een\u00e9s de type Transformer.","title":"Exemples"},{"location":"contextualized/#avantages","text":"tr\u00e8s performants, capturent le sens r\u00e9el du mot dans son contexte.","title":"Avantages"},{"location":"contextualized/#inconvenients","text":"lourds \u00e0 entra\u00eener et \u00e0 d\u00e9ployer, difficilement interpr\u00e9tables.","title":"Inconv\u00e9nients"},{"location":"creation/","text":"Comment les embeddings sont cr\u00e9\u00e9s Les embeddings sont g\u00e9n\u00e9ralement appris automatiquement \u00e0 partir de grands corpus de texte, en utilisant des techniques d\u2019apprentissage automatique ou d\u2019apprentissage profond. L\u2019objectif principal est de trouver une repr\u00e9sentation num\u00e9rique pour chaque mot (ou phrase, ou document) qui capture ses relations avec les autres mots dans le langage. \u00c9tapes g\u00e9n\u00e9rales de cr\u00e9ation d\u2019un embedding 1. Pr\u00e9paration des donn\u00e9es Un grand corpus de texte est collect\u00e9 (par exemple : Wikipedia, livres, articles...). Le texte est nettoy\u00e9, d\u00e9coup\u00e9 en phrases, puis en mots (tokenisation). Une \"fen\u00eatre de contexte\" est d\u00e9finie : par exemple, on peut regarder les 5 mots autour de chaque mot cible. 2. Construction d\u2019un objectif d\u2019apprentissage On choisit un objectif \u00e0 optimiser. Par exemple : Pr\u00e9dire un mot cible \u00e0 partir de son contexte (CBOW). Pr\u00e9dire le contexte \u00e0 partir d\u2019un mot cible (Skip-gram). Ou bien apprendre une fonction qui approxime les relations de cooccurrence entre mots (GloVe). Ce sont des t\u00e2ches simples, mais qui forcent le mod\u00e8le \u00e0 comprendre les relations entre mots pour r\u00e9ussir. 3. Entra\u00eenement d\u2019un mod\u00e8le On utilise un petit r\u00e9seau de neurones (dans Word2Vec) ou une architecture plus complexe (LSTM pour ELMo, Transformer pour BERT). Le mod\u00e8le ajuste progressivement les vecteurs associ\u00e9s \u00e0 chaque mot, de mani\u00e8re \u00e0 minimiser une fonction de perte (par exemple : erreur de pr\u00e9diction du mot). Pendant cet entra\u00eenement, chaque mot est associ\u00e9 \u00e0 un vecteur qui \u00e9volue \u00e0 chaque it\u00e9ration pour mieux refl\u00e9ter ses usages dans le corpus. 4. Extraction des vecteurs appris Une fois l\u2019entra\u00eenement termin\u00e9, chaque mot a un vecteur num\u00e9rique stable : c\u2019est son embedding. Ces vecteurs peuvent ensuite \u00eatre utilis\u00e9s dans d\u2019autres mod\u00e8les pour diff\u00e9rentes t\u00e2ches (analyse de sentiments, traduction automatique, r\u00e9sum\u00e9 de texte, etc.).","title":"Cr\u00e9ation des embeddings"},{"location":"creation/#comment-les-embeddings-sont-crees","text":"Les embeddings sont g\u00e9n\u00e9ralement appris automatiquement \u00e0 partir de grands corpus de texte, en utilisant des techniques d\u2019apprentissage automatique ou d\u2019apprentissage profond. L\u2019objectif principal est de trouver une repr\u00e9sentation num\u00e9rique pour chaque mot (ou phrase, ou document) qui capture ses relations avec les autres mots dans le langage. \u00c9tapes g\u00e9n\u00e9rales de cr\u00e9ation d\u2019un embedding","title":"Comment les embeddings sont cr\u00e9\u00e9s"},{"location":"creation/#1-preparation-des-donnees","text":"Un grand corpus de texte est collect\u00e9 (par exemple : Wikipedia, livres, articles...). Le texte est nettoy\u00e9, d\u00e9coup\u00e9 en phrases, puis en mots (tokenisation). Une \"fen\u00eatre de contexte\" est d\u00e9finie : par exemple, on peut regarder les 5 mots autour de chaque mot cible.","title":"1. Pr\u00e9paration des donn\u00e9es"},{"location":"creation/#2-construction-dun-objectif-dapprentissage","text":"On choisit un objectif \u00e0 optimiser. Par exemple : Pr\u00e9dire un mot cible \u00e0 partir de son contexte (CBOW). Pr\u00e9dire le contexte \u00e0 partir d\u2019un mot cible (Skip-gram). Ou bien apprendre une fonction qui approxime les relations de cooccurrence entre mots (GloVe). Ce sont des t\u00e2ches simples, mais qui forcent le mod\u00e8le \u00e0 comprendre les relations entre mots pour r\u00e9ussir.","title":"2. Construction d\u2019un objectif d\u2019apprentissage"},{"location":"creation/#3-entrainement-dun-modele","text":"On utilise un petit r\u00e9seau de neurones (dans Word2Vec) ou une architecture plus complexe (LSTM pour ELMo, Transformer pour BERT). Le mod\u00e8le ajuste progressivement les vecteurs associ\u00e9s \u00e0 chaque mot, de mani\u00e8re \u00e0 minimiser une fonction de perte (par exemple : erreur de pr\u00e9diction du mot). Pendant cet entra\u00eenement, chaque mot est associ\u00e9 \u00e0 un vecteur qui \u00e9volue \u00e0 chaque it\u00e9ration pour mieux refl\u00e9ter ses usages dans le corpus.","title":"3. Entra\u00eenement d\u2019un mod\u00e8le"},{"location":"creation/#4-extraction-des-vecteurs-appris","text":"Une fois l\u2019entra\u00eenement termin\u00e9, chaque mot a un vecteur num\u00e9rique stable : c\u2019est son embedding. Ces vecteurs peuvent ensuite \u00eatre utilis\u00e9s dans d\u2019autres mod\u00e8les pour diff\u00e9rentes t\u00e2ches (analyse de sentiments, traduction automatique, r\u00e9sum\u00e9 de texte, etc.).","title":"4. Extraction des vecteurs appris"},{"location":"ebauches/","text":"Ebauches","title":"Premi\u00e8res \u00e9bauches"},{"location":"ebauches/#ebauches","text":"","title":"Ebauches"},{"location":"frequency/","text":"Embeddings bas\u00e9s sur la fr\u00e9quence (Frequency-Based Embeddings) Ces m\u00e9thodes utilisent des statistiques de concurrence des mots dans un corpus. Elles reposent sur des matrices qui comptent le nombre de fois o\u00f9 des mots apparaissent ensemble dans des fen\u00eatres de texte. Exemples Count Vector : vecteur bas\u00e9 sur le nombre d\u2019occurrences de chaque mot dans un document. TF-IDF (Term Frequency-Inverse Document Frequency) : pond\u00e8re les mots en fonction de leur fr\u00e9quence dans le document et dans le corpus. LSA (Latent Semantic Analysis) :utilise la d\u00e9composition SVD pour extraire des concepts latents \u00e0 partir d\u2019une matrice terme-document. Avantages simples, interpr\u00e9tables. Inconv\u00e9nients matrices tr\u00e8s grandes et creuses, peu efficaces pour capturer des liens s\u00e9mantiques complexes.","title":"Frequency-Based Embeddings"},{"location":"frequency/#embeddings-bases-sur-la-frequence-frequency-based-embeddings","text":"Ces m\u00e9thodes utilisent des statistiques de concurrence des mots dans un corpus. Elles reposent sur des matrices qui comptent le nombre de fois o\u00f9 des mots apparaissent ensemble dans des fen\u00eatres de texte.","title":"Embeddings bas\u00e9s sur la fr\u00e9quence (Frequency-Based Embeddings)"},{"location":"frequency/#exemples","text":"Count Vector : vecteur bas\u00e9 sur le nombre d\u2019occurrences de chaque mot dans un document. TF-IDF (Term Frequency-Inverse Document Frequency) : pond\u00e8re les mots en fonction de leur fr\u00e9quence dans le document et dans le corpus. LSA (Latent Semantic Analysis) :utilise la d\u00e9composition SVD pour extraire des concepts latents \u00e0 partir d\u2019une matrice terme-document.","title":"Exemples"},{"location":"frequency/#avantages","text":"simples, interpr\u00e9tables.","title":"Avantages"},{"location":"frequency/#inconvenients","text":"matrices tr\u00e8s grandes et creuses, peu efficaces pour capturer des liens s\u00e9mantiques complexes.","title":"Inconv\u00e9nients"},{"location":"front-end_technos/","text":"Pourquoi nous avons choisi Astro ? Astro s\u2019est rapidement impos\u00e9 comme une solution particuli\u00e8rement pertinente pour notre projet, notamment gr\u00e2ce \u00e0 son approche orient\u00e9e performance par d\u00e9faut et sa philosophie content-first . Contrairement aux frameworks SPA traditionnels, Astro privil\u00e9gie le rendu HTML statique et limite drastiquement l\u2019envoi de JavaScript au navigateur. Cette caract\u00e9ristique correspond parfaitement \u00e0 notre besoin principal : afficher efficacement une grande quantit\u00e9 de contenu, tout en conservant la possibilit\u00e9 d\u2019ajouter de l\u2019interactivit\u00e9 de mani\u00e8re cibl\u00e9e. Analyse par crit\u00e8res Crit\u00e8re Observation Impact sur le projet Performance initiale Rendu HTML statique, 0 JavaScript par d\u00e9faut Temps de chargement ultra rapide d\u00e8s le premier affichage Poids du bundle JavaScript charg\u00e9 uniquement pour les composants interactifs R\u00e9duction du co\u00fbt r\u00e9seau et am\u00e9lioration significative de l\u2019UX Simplicit\u00e9 du code Structure claire et s\u00e9paration nette entre contenu, styles et logique Maintenance facilit\u00e9e et meilleure lisibilit\u00e9 SEO et accessibilit\u00e9 Pr\u00e9-rendu HTML natif R\u00e9f\u00e9rencement naturel optimis\u00e9 et meilleure accessibilit\u00e9 Facilit\u00e9 d\u2019int\u00e9gration Support hybride de multiples frameworks Int\u00e9gration fluide avec notre stack existante \u00c9cosyst\u00e8me en croissance Plugins officiels, documentation compl\u00e8te, communaut\u00e9 active P\u00e9rennit\u00e9 de la solution et \u00e9volutions \u00e0 long terme Nous avons retenu Astro car il permet de livrer une application extr\u00eamement performante d\u00e8s le premier rendu , tout en restant suffisamment flexible pour int\u00e9grer des composants dynamiques gr\u00e2ce au concept des Astro Islands . Cette approche dite \u00ab content-first \u00bb , qui priorise l\u2019affichage rapide des donn\u00e9es et du contenu, correspond parfaitement \u00e0 notre cas d\u2019usage : une majorit\u00e9 de pages statiques enrichies par quelques zones interactives cibl\u00e9es.","title":"Front-end"},{"location":"front-end_technos/#pourquoi-nous-avons-choisi-astro","text":"Astro s\u2019est rapidement impos\u00e9 comme une solution particuli\u00e8rement pertinente pour notre projet, notamment gr\u00e2ce \u00e0 son approche orient\u00e9e performance par d\u00e9faut et sa philosophie content-first . Contrairement aux frameworks SPA traditionnels, Astro privil\u00e9gie le rendu HTML statique et limite drastiquement l\u2019envoi de JavaScript au navigateur. Cette caract\u00e9ristique correspond parfaitement \u00e0 notre besoin principal : afficher efficacement une grande quantit\u00e9 de contenu, tout en conservant la possibilit\u00e9 d\u2019ajouter de l\u2019interactivit\u00e9 de mani\u00e8re cibl\u00e9e.","title":"Pourquoi nous avons choisi Astro ?"},{"location":"front-end_technos/#analyse-par-criteres","text":"Crit\u00e8re Observation Impact sur le projet Performance initiale Rendu HTML statique, 0 JavaScript par d\u00e9faut Temps de chargement ultra rapide d\u00e8s le premier affichage Poids du bundle JavaScript charg\u00e9 uniquement pour les composants interactifs R\u00e9duction du co\u00fbt r\u00e9seau et am\u00e9lioration significative de l\u2019UX Simplicit\u00e9 du code Structure claire et s\u00e9paration nette entre contenu, styles et logique Maintenance facilit\u00e9e et meilleure lisibilit\u00e9 SEO et accessibilit\u00e9 Pr\u00e9-rendu HTML natif R\u00e9f\u00e9rencement naturel optimis\u00e9 et meilleure accessibilit\u00e9 Facilit\u00e9 d\u2019int\u00e9gration Support hybride de multiples frameworks Int\u00e9gration fluide avec notre stack existante \u00c9cosyst\u00e8me en croissance Plugins officiels, documentation compl\u00e8te, communaut\u00e9 active P\u00e9rennit\u00e9 de la solution et \u00e9volutions \u00e0 long terme Nous avons retenu Astro car il permet de livrer une application extr\u00eamement performante d\u00e8s le premier rendu , tout en restant suffisamment flexible pour int\u00e9grer des composants dynamiques gr\u00e2ce au concept des Astro Islands . Cette approche dite \u00ab content-first \u00bb , qui priorise l\u2019affichage rapide des donn\u00e9es et du contenu, correspond parfaitement \u00e0 notre cas d\u2019usage : une majorit\u00e9 de pages statiques enrichies par quelques zones interactives cibl\u00e9es.","title":"Analyse par crit\u00e8res"},{"location":"inspiration/","text":"Inspiration pour les maquettes Pour trouver de l'inspiration pour les maquettes, nous avons demand\u00e9 \u00e0 diff\u00e9rentes ia de nous sugg\u00e9rer des maquettes, nous allons donc comparer, les diff\u00e9rents r\u00e9sultats, \u00e9tablir leurs forces et faiblesses afin de cr\u00e9er une maquette finales. Le prompt que nous avons utilis\u00e9 est le suivant: Propose-moi un design pour une application web qui me permette de cr\u00e9er un glossaire m\u00e9tier. Je voudrais pouvoir ajouter un mot, sa d\u00e9finition, ainsi qu'un contexte li\u00e9 \u00e0 ce mot. Il faudrait aussi que je puisse entrer des synonymes et des antonymes, et que l'IA puisse en sugg\u00e9rer . Je voudrais avoir la possibilit\u00e9 de choisir les synonymes les plus pertinents. De plus, en fonction des mots d\u00e9j\u00e0 enregistr\u00e9s, l\u2019application devrait pouvoir proposer des contextes associ\u00e9s. deepseek La maquette propos\u00e9e par Deepseek est correcte mais trop charg\u00e9e. chatgpt ChatGPT a propos\u00e9 une maquette assez similaire \u00e0 celle de Deepseek mais avec comme principale diff\u00e9rence la pr\u00e9sentation des diff\u00e9rents termes qui se font sous forme d'un tableur, ce qui nous int\u00e9resse plus. claude Claude a g\u00e9n\u00e9r\u00e9 une maquette trop simpliste et vide avec des couleurs \u00e9tranges. gemini Gemini a propos\u00e9 un desgin r\u00e9pondant certaines de nos exigeances, nous nous inspirons de plusieurs \u00e9l\u00e9ments de ce design. grok Le design de Grok r\u00e9pond quant \u00e0 lui presque parfaitement \u00e0 nos besoins \u00e0 l'exception de la pr\u00e9sentation des termes existants, il nous servira d'inspiration principale. mistral La pr\u00e9sentation de mistral est pl\u00fbtot archa\u00efque. qwen Qwen nous a propos\u00e9 un design assez vide et simple, insuffisant pour en tirer de l'inspiration. perplexity perplexity nous pr\u00e9sente une interface avec les m\u00eames d\u00e9faut que celle de qwen. stitch . Stitch \u00e9tant une intelligence artificielle sp\u00e9cialis\u00e9e en design, elle nous propose plusieurs maquettes fournies assez semblables aux designs modernes mais est assez impersonnelles, cependant cela servira d'inspiration principale pour le tableur.","title":"Inspiration"},{"location":"inspiration/#inspiration-pour-les-maquettes","text":"Pour trouver de l'inspiration pour les maquettes, nous avons demand\u00e9 \u00e0 diff\u00e9rentes ia de nous sugg\u00e9rer des maquettes, nous allons donc comparer, les diff\u00e9rents r\u00e9sultats, \u00e9tablir leurs forces et faiblesses afin de cr\u00e9er une maquette finales. Le prompt que nous avons utilis\u00e9 est le suivant: Propose-moi un design pour une application web qui me permette de cr\u00e9er un glossaire m\u00e9tier. Je voudrais pouvoir ajouter un mot, sa d\u00e9finition, ainsi qu'un contexte li\u00e9 \u00e0 ce mot. Il faudrait aussi que je puisse entrer des synonymes et des antonymes, et que l'IA puisse en sugg\u00e9rer . Je voudrais avoir la possibilit\u00e9 de choisir les synonymes les plus pertinents. De plus, en fonction des mots d\u00e9j\u00e0 enregistr\u00e9s, l\u2019application devrait pouvoir proposer des contextes associ\u00e9s.","title":"Inspiration pour les maquettes"},{"location":"inspiration/#deepseek","text":"La maquette propos\u00e9e par Deepseek est correcte mais trop charg\u00e9e.","title":"deepseek"},{"location":"inspiration/#chatgpt","text":"ChatGPT a propos\u00e9 une maquette assez similaire \u00e0 celle de Deepseek mais avec comme principale diff\u00e9rence la pr\u00e9sentation des diff\u00e9rents termes qui se font sous forme d'un tableur, ce qui nous int\u00e9resse plus.","title":"chatgpt"},{"location":"inspiration/#claude","text":"Claude a g\u00e9n\u00e9r\u00e9 une maquette trop simpliste et vide avec des couleurs \u00e9tranges.","title":"claude"},{"location":"inspiration/#gemini","text":"Gemini a propos\u00e9 un desgin r\u00e9pondant certaines de nos exigeances, nous nous inspirons de plusieurs \u00e9l\u00e9ments de ce design.","title":"gemini"},{"location":"inspiration/#grok","text":"Le design de Grok r\u00e9pond quant \u00e0 lui presque parfaitement \u00e0 nos besoins \u00e0 l'exception de la pr\u00e9sentation des termes existants, il nous servira d'inspiration principale.","title":"grok"},{"location":"inspiration/#mistral","text":"La pr\u00e9sentation de mistral est pl\u00fbtot archa\u00efque.","title":"mistral"},{"location":"inspiration/#qwen","text":"Qwen nous a propos\u00e9 un design assez vide et simple, insuffisant pour en tirer de l'inspiration.","title":"qwen"},{"location":"inspiration/#perplexity","text":"perplexity nous pr\u00e9sente une interface avec les m\u00eames d\u00e9faut que celle de qwen.","title":"perplexity"},{"location":"inspiration/#stitch","text":". Stitch \u00e9tant une intelligence artificielle sp\u00e9cialis\u00e9e en design, elle nous propose plusieurs maquettes fournies assez semblables aux designs modernes mais est assez impersonnelles, cependant cela servira d'inspiration principale pour le tableur.","title":"stitch"},{"location":"installation/","text":"Installation Linux Sur Linux, le projet se pr\u00e9sente sous forme de fichier AppImage, un format qui peut \u00eatre lanc\u00e9 sur n'importe quelle distribution linux. Pour lancer le projet, il suffit de t\u00e9l\u00e9charger le fichier et double-cliquer dessus. Windows Sous Windows, le projet se pr\u00e9sent sous forme d'un installateur MSI. Il suffit de double cliquer dessus et de suivre les instructions pour installer l'application. MacOS Sur MacOS, le projet se pr\u00e9sente sous forme de fichier DMG. Pour l'installer, il faut le t\u00e9l\u00e9charger puis le mettre dans le dossier des applications de MacOS.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#linux","text":"Sur Linux, le projet se pr\u00e9sente sous forme de fichier AppImage, un format qui peut \u00eatre lanc\u00e9 sur n'importe quelle distribution linux. Pour lancer le projet, il suffit de t\u00e9l\u00e9charger le fichier et double-cliquer dessus.","title":"Linux"},{"location":"installation/#windows","text":"Sous Windows, le projet se pr\u00e9sent sous forme d'un installateur MSI. Il suffit de double cliquer dessus et de suivre les instructions pour installer l'application.","title":"Windows"},{"location":"installation/#macos","text":"Sur MacOS, le projet se pr\u00e9sente sous forme de fichier DMG. Pour l'installer, il faut le t\u00e9l\u00e9charger puis le mettre dans le dossier des applications de MacOS.","title":"MacOS"},{"location":"integration-js_technos/","text":"Pourquoi nous avons choisi SolidJS ? Certaines fonctionnalit\u00e9s de l\u2019application n\u00e9cessitent une interactivit\u00e9 locale, notamment pour des tableaux modifiables , des formulaires dynamiques ou des composants n\u00e9cessitant des mises \u00e0 jour fr\u00e9quentes de l\u2019\u00e9tat. Pour r\u00e9pondre \u00e0 ces besoins sp\u00e9cifiques sans alourdir inutilement l\u2019ensemble de l\u2019application, nous avons choisi SolidJS , int\u00e9gr\u00e9 via le syst\u00e8me des Astro Islands . Nos motivations principales Crit\u00e8re Observation Avantage Performance runtime R\u00e9activit\u00e9 fine sans Virtual DOM Exp\u00e9rience utilisateur fluide et instantan\u00e9e Poids du bundle Framework tr\u00e8s l\u00e9ger Interactivit\u00e9 sans compromettre la vitesse globale Simplicit\u00e9 d\u2019int\u00e9gration Compatibilit\u00e9 native avec Astro Aucun surco\u00fbt de configuration API moderne et famili\u00e8re Syntaxe proche de React Courbe d\u2019apprentissage rapide pour l\u2019\u00e9quipe SolidJS n\u2019est charg\u00e9 que l\u00e0 o\u00f9 il est strictement n\u00e9cessaire . Le reste du site demeure statique et optimis\u00e9, ce qui nous permet de minimiser la quantit\u00e9 de JavaScript envoy\u00e9e au client , tout en conservant une exp\u00e9rience utilisateur moderne, r\u00e9active et coh\u00e9rente.","title":"Int\u00e9gration JS"},{"location":"integration-js_technos/#pourquoi-nous-avons-choisi-solidjs","text":"Certaines fonctionnalit\u00e9s de l\u2019application n\u00e9cessitent une interactivit\u00e9 locale, notamment pour des tableaux modifiables , des formulaires dynamiques ou des composants n\u00e9cessitant des mises \u00e0 jour fr\u00e9quentes de l\u2019\u00e9tat. Pour r\u00e9pondre \u00e0 ces besoins sp\u00e9cifiques sans alourdir inutilement l\u2019ensemble de l\u2019application, nous avons choisi SolidJS , int\u00e9gr\u00e9 via le syst\u00e8me des Astro Islands .","title":"Pourquoi nous avons choisi SolidJS ?"},{"location":"integration-js_technos/#nos-motivations-principales","text":"Crit\u00e8re Observation Avantage Performance runtime R\u00e9activit\u00e9 fine sans Virtual DOM Exp\u00e9rience utilisateur fluide et instantan\u00e9e Poids du bundle Framework tr\u00e8s l\u00e9ger Interactivit\u00e9 sans compromettre la vitesse globale Simplicit\u00e9 d\u2019int\u00e9gration Compatibilit\u00e9 native avec Astro Aucun surco\u00fbt de configuration API moderne et famili\u00e8re Syntaxe proche de React Courbe d\u2019apprentissage rapide pour l\u2019\u00e9quipe SolidJS n\u2019est charg\u00e9 que l\u00e0 o\u00f9 il est strictement n\u00e9cessaire . Le reste du site demeure statique et optimis\u00e9, ce qui nous permet de minimiser la quantit\u00e9 de JavaScript envoy\u00e9e au client , tout en conservant une exp\u00e9rience utilisateur moderne, r\u00e9active et coh\u00e9rente.","title":"Nos motivations principales"},{"location":"maquettes/","text":"Documentation du processus de conception Notre approche de validation continue Nous avons adopt\u00e9 une m\u00e9thodologie de validation continue pour la conception de nos maquettes. Notre processus suit un cycle r\u00e9gulier : nous concevons une page sur Figma, puis pr\u00e9sentons notre travail \u00e0 nos clients pour obtenir ses retours. Ces sessions de validation, nous permettent d'ajuster r\u00e9guli\u00e8rement notre direction et d'am\u00e9liorer progressivement la qualit\u00e9 de nos interfaces. Cette approche it\u00e9rative nous a \u00e9vit\u00e9 les d\u00e9rives de conception et nous a fait gagner un temps pr\u00e9cieux. En corrigeant rapidement les erreurs identifi\u00e9es par nos clients, nous avons pu avancer efficacement sans avoir \u00e0 refondre des sections enti\u00e8res du projet. Notre workflow sur Figma Notre travail sur Figma est structur\u00e9 pour faciliter la collaboration. Nous utilisons les composants principaux et les variantes pour maintenir une biblioth\u00e8que coh\u00e9rente. Chaque page con\u00e7ue inclut plusieurs \u00e9tats d'interaction, et nous annotons syst\u00e9matiquement les comportements attendus. Nous avan\u00e7ons par niveaux de complexit\u00e9 croissantes. Nous validons d'abord la structure et l'agencement avec des wireframes simples, puis nous affinons progressivement vers des maquettes d\u00e9taill\u00e9es. Les b\u00e9n\u00e9fices de notre m\u00e9thode Cette m\u00e9thode de validation r\u00e9guli\u00e8re nous a apport\u00e9 plusieurs avantages. Elle nous a permis d'appliquer imm\u00e9diatement les concepts th\u00e9oriques vus en cours \u00e0 notre projet concret. Les retours de nos clients nous ont aid\u00e9s \u00e0 distinguer les bonnes pratiques des simples pr\u00e9f\u00e9rences esth\u00e9tiques. Nous avons \u00e9galement d\u00e9velopp\u00e9 notre capacit\u00e9 \u00e0 recevoir et int\u00e9grer les critiques constructives. Au fil des sessions, nous sommes devenus plus efficaces pour d\u00e9fendre nos choix de design avec des arguments solides tout en restant ouverts aux suggestions d'am\u00e9lioration. Conclusion Notre processus de validation continue s'est r\u00e9v\u00e9l\u00e9 extr\u00eamement efficace pour mener \u00e0 bien la conception de nos maquettes. En int\u00e9grant r\u00e9guli\u00e8rement les id\u00e9es de nos clients, nous avons produit des interfaces de qualit\u00e9 tout en d\u00e9veloppant nos comp\u00e9tences pratiques en design d'exp\u00e9rience utilisateur. Cette m\u00e9thode collaborative nous a permis d'avancer avec confiance, sachant que notre travail \u00e9tait r\u00e9guli\u00e8rement align\u00e9 avec les attentes p\u00e9dagogiques et les standards professionnels. Les maquettes finales refl\u00e8tent cette approche it\u00e9rative, combinant notre travail d'\u00e9quipe et les pr\u00e9cieux retours qui ont guid\u00e9 notre progression.","title":"Maquettes"},{"location":"maquettes/#documentation-du-processus-de-conception","text":"","title":"Documentation du processus de conception"},{"location":"maquettes/#notre-approche-de-validation-continue","text":"Nous avons adopt\u00e9 une m\u00e9thodologie de validation continue pour la conception de nos maquettes. Notre processus suit un cycle r\u00e9gulier : nous concevons une page sur Figma, puis pr\u00e9sentons notre travail \u00e0 nos clients pour obtenir ses retours. Ces sessions de validation, nous permettent d'ajuster r\u00e9guli\u00e8rement notre direction et d'am\u00e9liorer progressivement la qualit\u00e9 de nos interfaces. Cette approche it\u00e9rative nous a \u00e9vit\u00e9 les d\u00e9rives de conception et nous a fait gagner un temps pr\u00e9cieux. En corrigeant rapidement les erreurs identifi\u00e9es par nos clients, nous avons pu avancer efficacement sans avoir \u00e0 refondre des sections enti\u00e8res du projet.","title":"Notre approche de validation continue"},{"location":"maquettes/#notre-workflow-sur-figma","text":"Notre travail sur Figma est structur\u00e9 pour faciliter la collaboration. Nous utilisons les composants principaux et les variantes pour maintenir une biblioth\u00e8que coh\u00e9rente. Chaque page con\u00e7ue inclut plusieurs \u00e9tats d'interaction, et nous annotons syst\u00e9matiquement les comportements attendus. Nous avan\u00e7ons par niveaux de complexit\u00e9 croissantes. Nous validons d'abord la structure et l'agencement avec des wireframes simples, puis nous affinons progressivement vers des maquettes d\u00e9taill\u00e9es.","title":"Notre workflow sur Figma"},{"location":"maquettes/#les-benefices-de-notre-methode","text":"Cette m\u00e9thode de validation r\u00e9guli\u00e8re nous a apport\u00e9 plusieurs avantages. Elle nous a permis d'appliquer imm\u00e9diatement les concepts th\u00e9oriques vus en cours \u00e0 notre projet concret. Les retours de nos clients nous ont aid\u00e9s \u00e0 distinguer les bonnes pratiques des simples pr\u00e9f\u00e9rences esth\u00e9tiques. Nous avons \u00e9galement d\u00e9velopp\u00e9 notre capacit\u00e9 \u00e0 recevoir et int\u00e9grer les critiques constructives. Au fil des sessions, nous sommes devenus plus efficaces pour d\u00e9fendre nos choix de design avec des arguments solides tout en restant ouverts aux suggestions d'am\u00e9lioration.","title":"Les b\u00e9n\u00e9fices de notre m\u00e9thode"},{"location":"maquettes/#conclusion","text":"Notre processus de validation continue s'est r\u00e9v\u00e9l\u00e9 extr\u00eamement efficace pour mener \u00e0 bien la conception de nos maquettes. En int\u00e9grant r\u00e9guli\u00e8rement les id\u00e9es de nos clients, nous avons produit des interfaces de qualit\u00e9 tout en d\u00e9veloppant nos comp\u00e9tences pratiques en design d'exp\u00e9rience utilisateur. Cette m\u00e9thode collaborative nous a permis d'avancer avec confiance, sachant que notre travail \u00e9tait r\u00e9guli\u00e8rement align\u00e9 avec les attentes p\u00e9dagogiques et les standards professionnels. Les maquettes finales refl\u00e8tent cette approche it\u00e9rative, combinant notre travail d'\u00e9quipe et les pr\u00e9cieux retours qui ont guid\u00e9 notre progression.","title":"Conclusion"},{"location":"parser/","text":"Parser La suite de la SAE se concentrera sur de l'analyse de code, c'est donc pour cela qu'il est n\u00e9cessaire de d\u00e9tenir ce qui s'appelle un parser. L'action de parser se r\u00e9f\u00e8re \u00e0 l'analyse syntaxique, c'est-\u00e0-dire mettre en \u00e9vidence la structure d'un texte. Cela est utilis\u00e9 dans de nombreux domaines, que ce soit dans les langues, les maths ou bien ce qui nous int\u00e9resse, la programmation. Dans notre cas, cela consiste \u00e0 extraire les mots cl\u00e9s non inh\u00e9rents aux langages donc d\u00e9finis par les utilisateurs pour ensuite relever les occurrences. Apr\u00e8s avoir effectu\u00e9 des tests en utilisant les expressions r\u00e9guli\u00e8res, ceux-ci se sont r\u00e9v\u00e9l\u00e9s non concluants car trop complexes et pas assez fiables. Nous sommes donc pass\u00e9s sur la biblioth\u00e8que tree-sitter permettant de r\u00e9aliser notre besoin d'une mani\u00e8re assez simple en d\u00e9finissant simplement, pour chaque langage cibl\u00e9, le type de mot cl\u00e9 que nous souhaitons r\u00e9cup\u00e9rer. C'est donc comme cela que nous avons pu r\u00e9aliser des fonctions Python plac\u00e9es dans le back-end permettant de prendre un dossier de code, dans un premier temps uniquement en Java, et d'en extraire les termes m\u00e9tier tri\u00e9s par le nombre d'occurrences et donc leur probable importance. Impl\u00e9ment\u00e9s dans l'application, cela permet de cr\u00e9er une base afin de remplir un glossaire.","title":"Parser"},{"location":"parser/#parser","text":"La suite de la SAE se concentrera sur de l'analyse de code, c'est donc pour cela qu'il est n\u00e9cessaire de d\u00e9tenir ce qui s'appelle un parser. L'action de parser se r\u00e9f\u00e8re \u00e0 l'analyse syntaxique, c'est-\u00e0-dire mettre en \u00e9vidence la structure d'un texte. Cela est utilis\u00e9 dans de nombreux domaines, que ce soit dans les langues, les maths ou bien ce qui nous int\u00e9resse, la programmation. Dans notre cas, cela consiste \u00e0 extraire les mots cl\u00e9s non inh\u00e9rents aux langages donc d\u00e9finis par les utilisateurs pour ensuite relever les occurrences. Apr\u00e8s avoir effectu\u00e9 des tests en utilisant les expressions r\u00e9guli\u00e8res, ceux-ci se sont r\u00e9v\u00e9l\u00e9s non concluants car trop complexes et pas assez fiables. Nous sommes donc pass\u00e9s sur la biblioth\u00e8que tree-sitter permettant de r\u00e9aliser notre besoin d'une mani\u00e8re assez simple en d\u00e9finissant simplement, pour chaque langage cibl\u00e9, le type de mot cl\u00e9 que nous souhaitons r\u00e9cup\u00e9rer. C'est donc comme cela que nous avons pu r\u00e9aliser des fonctions Python plac\u00e9es dans le back-end permettant de prendre un dossier de code, dans un premier temps uniquement en Java, et d'en extraire les termes m\u00e9tier tri\u00e9s par le nombre d'occurrences et donc leur probable importance. Impl\u00e9ment\u00e9s dans l'application, cela permet de cr\u00e9er une base afin de remplir un glossaire.","title":"Parser"},{"location":"prediction/","text":"Embeddings pr\u00e9dictifs (Prediction-Based Embeddings) Ces mod\u00e8les apprennent les vecteurs en pr\u00e9voyant un mot \u00e0 partir de son contexte ou l\u2019inverse. Utilisent des r\u00e9seaux de neurones simples pour cr\u00e9er des repr\u00e9sentations distribu\u00e9es. Exemples Word2Vec Skip-gram : pr\u00e9dit les mots du contexte \u00e0 partir du mot cible. CBOW (Continuous Bag of Words) : pr\u00e9dit le mot cible \u00e0 partir du contexte. GloVe : combine approche de cooccurrence et apprentissage pr\u00e9dictif ; s\u2019appuie sur la probabilit\u00e9 relative de cooccurrence entre mots. Avantages efficaces, rapides \u00e0 entra\u00eener, bonnes performances sur les similarit\u00e9s s\u00e9mantiques. Inconv\u00e9nients un seul vecteur par mot, pas de prise en compte du contexte (un mot a toujours le m\u00eame vecteur, quel que soit son sens dans la phrase).","title":"Prediction-Based Embeddings"},{"location":"prediction/#embeddings-predictifs-prediction-based-embeddings","text":"Ces mod\u00e8les apprennent les vecteurs en pr\u00e9voyant un mot \u00e0 partir de son contexte ou l\u2019inverse. Utilisent des r\u00e9seaux de neurones simples pour cr\u00e9er des repr\u00e9sentations distribu\u00e9es.","title":"Embeddings pr\u00e9dictifs (Prediction-Based Embeddings)"},{"location":"prediction/#exemples","text":"","title":"Exemples"},{"location":"prediction/#word2vec","text":"Skip-gram : pr\u00e9dit les mots du contexte \u00e0 partir du mot cible. CBOW (Continuous Bag of Words) : pr\u00e9dit le mot cible \u00e0 partir du contexte. GloVe : combine approche de cooccurrence et apprentissage pr\u00e9dictif ; s\u2019appuie sur la probabilit\u00e9 relative de cooccurrence entre mots.","title":"Word2Vec"},{"location":"prediction/#avantages","text":"efficaces, rapides \u00e0 entra\u00eener, bonnes performances sur les similarit\u00e9s s\u00e9mantiques.","title":"Avantages"},{"location":"prediction/#inconvenients","text":"un seul vecteur par mot, pas de prise en compte du contexte (un mot a toujours le m\u00eame vecteur, quel que soit son sens dans la phrase).","title":"Inconv\u00e9nients"},{"location":"experimentations/api_visualisations/","text":"API & Visualisations Nouvelle m\u00e9thode La nouvelle m\u00e9thode fonctionne comme suit: On commence par r\u00e9cup\u00e9rer les synonymes du mot depuis des API, puis on emb\u00e8de le mot (avec son contexte) ainsi que les synonymes. On classe ensuite les synonymes selon leur proximit\u00e9 avec l'embedding du mot et on ne garde que les meilleurs. On peut aussi faire la m\u00eame chose avec des antonymes. Comparaison MiniLM et Word2Vec Pour d\u00e9terminer quel \u00e9tait le meilleur mod\u00e8le pour cette t\u00e2che, nous avons cr\u00e9\u00e9 une visualisation afin de voir lequel rapprochait le mieux les diff\u00e9rents synonymes. Dans cette visualisation, 4 groupes de 3 mots sont affich\u00e9s, en anglais et en fran\u00e7ais (sauf pour Word2Vec, dont le corpus utilis\u00e9 est exclusivement anglais). Word2Vec (mots anglais) MiniLM (mots anglais) MiniLM (mots fran\u00e7ais) On peut voir que, pour Word2Vec deux groupes (\u00ab gems \u00bb et \u00ab button \u00bb) sont bien regroup\u00e9s, mais pas les deux autres. Pour MiniLM, les groupes sont bien regroup\u00e9s en anglais, mais pas en fran\u00e7ais. Au vu de ces r\u00e9sultats, nous avons d\u00e9cid\u00e9 d'abandonner compl\u00e8tement Word2Vec et d'utiliser MiniLM pour la suite. Strat\u00e9gie d'embedding \u00c0 l'origine, nous utilisions la m\u00eame strat\u00e9gie pour embedder les mots avec MiniLM qu'avec Word2Vec: chaque mot du contexte (tous des synonymes les uns des autres lors des tests) \u00e9tait embedd\u00e9 individuellement, puis la moyenne des vecteurs \u00e9tait utilis\u00e9e comme r\u00e9sultat (m\u00e9thode 1). Nous avons d\u00e9cid\u00e9 de comparer cette m\u00e9thode avec une autre, plus adapt\u00e9e \u00e0 un mod\u00e8le qui prend en compte le contexte: concat\u00e9ner tous les mots du contexte, s\u00e9par\u00e9s par des virgules, puis embedder le tout d'un coup (m\u00e9thode 2). Pour comparer les deux m\u00e9thodes, nous avons lanc\u00e9 la recherche de synonymes sur 4 groupes de 3 mots: Groupe 1: home , residence , house Groupe 2: button , zipper , latch Groupe 3: penalty , sanction , sentence Groupe 4: ruby , emerald , sapphire Pour chaque groupe, on r\u00e9cup\u00e8re la liste des synonymes et on les affiches avec leur score et leur nombre d'occurrences (le m\u00eame synonyme peut appara\u00eetre dans plusieurs API, et plusieurs fois dans la m\u00eame API). Voici les r\u00e9sultats: Groupe 1 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences abidance 0.7958 1 abidance 0.9731 1 enclose 0.7688 2 manse 0.9287 1 rezidentura 0.7639 1 enclose 0.9095 2 menage 0.7485 2 menage 0.9082 2 manse 0.7222 1 rezidentura 0.8941 1 sign 0.6891 1 sign 0.8894 1 base 0.6771 1 firm 0.8893 1 accommodate 0.6673 2 theater 0.8865 1 firm 0.6666 1 accommodate 0.8775 2 tenement 0.6593 2 harbor 0.8652 2 harbor 0.6489 2 base 0.8589 1 theater 0.6380 1 harbour 0.8277 2 harbour 0.6236 2 tenement 0.8241 2 domicile 0.6151 3 shop 0.8083 4 shop 0.5999 4 put up 0.7819 2 put up 0.5895 2 store 0.7787 2 store 0.5737 2 host 0.7711 2 host 0.5590 2 domicile 0.7245 3 abode 0.5245 4 abode 0.6901 4 homeward 0.6206 2 residency 0.5429 2 Groupe 2 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences endpin 0.7081 1 push 0.9102 1 adjuster 0.6553 1 endpin 0.9008 1 push 0.6520 1 blow 0.8806 1 slide fastener 0.6389 3 adjuster 0.8092 1 blow 0.6132 1 clit 0.7725 1 clit 0.5455 1 slide fastener 0.7202 3 zip fastener 0.5384 2 zip 0.6318 2 endbutton 0.5212 1 zip up 0.6314 1 zip up 0.5019 1 endbutton 0.5855 1 zip fastener 0.5750 2 Groupe 3 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences embargo 0.7105 1 embargo 0.8740 1 estoppel 0.7021 1 estoppel 0.8688 1 boycott 0.6608 1 boycott 0.8348 1 interdiction 0.6523 1 interdiction 0.8293 1 taboo 0.6287 1 taboo 0.7957 1 countenance 0.6153 1 countenance 0.7884 1 injunction 0.5889 1 proscription 0.7777 1 proscription 0.5875 1 authority 0.7736 1 punition 0.5458 2 punition 0.7174 2 authority 0.5444 1 injunction 0.6887 1 ban 0.6302 1 verdict 0.6016 2 condemn 0.5701 1 sentence 0.5591 2 pass sentence 0.5417 1 conviction 0.5352 3 Groupe 4 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences smaragd 0.7336 2 smaragd 0.8328 2 minionette 0.7200 2 minionette 0.7985 2 chromatic 0.6947 2 azure 0.7662 1 azure 0.6637 1 agate 0.7341 3 ruddy 0.6277 1 chromatic 0.7321 2 agate 0.6240 3 ruddy 0.7072 1 crimson 0.6023 1 crimson 0.6362 1 carmine 0.5153 1 rubi 0.6085 2 rubi 0.5029 2 carmine 0.5928 1 On voit rapidement que la m\u00e9thode 2 a tendance \u00e0 attribuer des scores plus \u00e9lev\u00e9s aux synonymes, ce qui n'est pas grave: on peut simplement augmenter le seuil minimal requis pour qu'un synonyme soit retenu (lors des tests, tous les synonymes avec un score sup\u00e9rieur \u00e0 0.5 \u00e9taient retenus). On remarque aussi que les scores fournis par la m\u00e9thode 2 sont globalement meilleurs. Nous avons donc choisi d'utiliser cette m\u00e9thode. Probl\u00e8mes Malheureusement, apr\u00e8s avoir fait plus de tests, la qualit\u00e9 des synonymes laissait \u00e0 d\u00e9sirer, principalement parce que les API ne renvoyaient pas des synonymes de qualit\u00e9 en premier lieu, probl\u00e8me que le filtrage ne suffisait pas \u00e0 r\u00e9soudre. La d\u00e9pendance \u00e0 des API est aussi probl\u00e9matique car elle n\u00e9cessite une connexion internet et suppose que les API soient fonctionnelles. Nous avons donc d\u00e9cid\u00e9 de changer de m\u00e9thode, comme pr\u00e9sent\u00e9 dans la partie suivante.","title":"API & Visualisations"},{"location":"experimentations/api_visualisations/#api-visualisations","text":"","title":"API &amp; Visualisations"},{"location":"experimentations/api_visualisations/#nouvelle-methode","text":"La nouvelle m\u00e9thode fonctionne comme suit: On commence par r\u00e9cup\u00e9rer les synonymes du mot depuis des API, puis on emb\u00e8de le mot (avec son contexte) ainsi que les synonymes. On classe ensuite les synonymes selon leur proximit\u00e9 avec l'embedding du mot et on ne garde que les meilleurs. On peut aussi faire la m\u00eame chose avec des antonymes.","title":"Nouvelle m\u00e9thode"},{"location":"experimentations/api_visualisations/#comparaison-minilm-et-word2vec","text":"Pour d\u00e9terminer quel \u00e9tait le meilleur mod\u00e8le pour cette t\u00e2che, nous avons cr\u00e9\u00e9 une visualisation afin de voir lequel rapprochait le mieux les diff\u00e9rents synonymes. Dans cette visualisation, 4 groupes de 3 mots sont affich\u00e9s, en anglais et en fran\u00e7ais (sauf pour Word2Vec, dont le corpus utilis\u00e9 est exclusivement anglais). Word2Vec (mots anglais) MiniLM (mots anglais) MiniLM (mots fran\u00e7ais) On peut voir que, pour Word2Vec deux groupes (\u00ab gems \u00bb et \u00ab button \u00bb) sont bien regroup\u00e9s, mais pas les deux autres. Pour MiniLM, les groupes sont bien regroup\u00e9s en anglais, mais pas en fran\u00e7ais. Au vu de ces r\u00e9sultats, nous avons d\u00e9cid\u00e9 d'abandonner compl\u00e8tement Word2Vec et d'utiliser MiniLM pour la suite.","title":"Comparaison MiniLM et Word2Vec"},{"location":"experimentations/api_visualisations/#strategie-dembedding","text":"\u00c0 l'origine, nous utilisions la m\u00eame strat\u00e9gie pour embedder les mots avec MiniLM qu'avec Word2Vec: chaque mot du contexte (tous des synonymes les uns des autres lors des tests) \u00e9tait embedd\u00e9 individuellement, puis la moyenne des vecteurs \u00e9tait utilis\u00e9e comme r\u00e9sultat (m\u00e9thode 1). Nous avons d\u00e9cid\u00e9 de comparer cette m\u00e9thode avec une autre, plus adapt\u00e9e \u00e0 un mod\u00e8le qui prend en compte le contexte: concat\u00e9ner tous les mots du contexte, s\u00e9par\u00e9s par des virgules, puis embedder le tout d'un coup (m\u00e9thode 2). Pour comparer les deux m\u00e9thodes, nous avons lanc\u00e9 la recherche de synonymes sur 4 groupes de 3 mots: Groupe 1: home , residence , house Groupe 2: button , zipper , latch Groupe 3: penalty , sanction , sentence Groupe 4: ruby , emerald , sapphire Pour chaque groupe, on r\u00e9cup\u00e8re la liste des synonymes et on les affiches avec leur score et leur nombre d'occurrences (le m\u00eame synonyme peut appara\u00eetre dans plusieurs API, et plusieurs fois dans la m\u00eame API). Voici les r\u00e9sultats: Groupe 1 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences abidance 0.7958 1 abidance 0.9731 1 enclose 0.7688 2 manse 0.9287 1 rezidentura 0.7639 1 enclose 0.9095 2 menage 0.7485 2 menage 0.9082 2 manse 0.7222 1 rezidentura 0.8941 1 sign 0.6891 1 sign 0.8894 1 base 0.6771 1 firm 0.8893 1 accommodate 0.6673 2 theater 0.8865 1 firm 0.6666 1 accommodate 0.8775 2 tenement 0.6593 2 harbor 0.8652 2 harbor 0.6489 2 base 0.8589 1 theater 0.6380 1 harbour 0.8277 2 harbour 0.6236 2 tenement 0.8241 2 domicile 0.6151 3 shop 0.8083 4 shop 0.5999 4 put up 0.7819 2 put up 0.5895 2 store 0.7787 2 store 0.5737 2 host 0.7711 2 host 0.5590 2 domicile 0.7245 3 abode 0.5245 4 abode 0.6901 4 homeward 0.6206 2 residency 0.5429 2 Groupe 2 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences endpin 0.7081 1 push 0.9102 1 adjuster 0.6553 1 endpin 0.9008 1 push 0.6520 1 blow 0.8806 1 slide fastener 0.6389 3 adjuster 0.8092 1 blow 0.6132 1 clit 0.7725 1 clit 0.5455 1 slide fastener 0.7202 3 zip fastener 0.5384 2 zip 0.6318 2 endbutton 0.5212 1 zip up 0.6314 1 zip up 0.5019 1 endbutton 0.5855 1 zip fastener 0.5750 2 Groupe 3 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences embargo 0.7105 1 embargo 0.8740 1 estoppel 0.7021 1 estoppel 0.8688 1 boycott 0.6608 1 boycott 0.8348 1 interdiction 0.6523 1 interdiction 0.8293 1 taboo 0.6287 1 taboo 0.7957 1 countenance 0.6153 1 countenance 0.7884 1 injunction 0.5889 1 proscription 0.7777 1 proscription 0.5875 1 authority 0.7736 1 punition 0.5458 2 punition 0.7174 2 authority 0.5444 1 injunction 0.6887 1 ban 0.6302 1 verdict 0.6016 2 condemn 0.5701 1 sentence 0.5591 2 pass sentence 0.5417 1 conviction 0.5352 3 Groupe 4 M\u00e9thode 1 M\u00e9thode 2 Synonyme Score Occurrences Synonyme Score Occurrences smaragd 0.7336 2 smaragd 0.8328 2 minionette 0.7200 2 minionette 0.7985 2 chromatic 0.6947 2 azure 0.7662 1 azure 0.6637 1 agate 0.7341 3 ruddy 0.6277 1 chromatic 0.7321 2 agate 0.6240 3 ruddy 0.7072 1 crimson 0.6023 1 crimson 0.6362 1 carmine 0.5153 1 rubi 0.6085 2 rubi 0.5029 2 carmine 0.5928 1 On voit rapidement que la m\u00e9thode 2 a tendance \u00e0 attribuer des scores plus \u00e9lev\u00e9s aux synonymes, ce qui n'est pas grave: on peut simplement augmenter le seuil minimal requis pour qu'un synonyme soit retenu (lors des tests, tous les synonymes avec un score sup\u00e9rieur \u00e0 0.5 \u00e9taient retenus). On remarque aussi que les scores fournis par la m\u00e9thode 2 sont globalement meilleurs. Nous avons donc choisi d'utiliser cette m\u00e9thode.","title":"Strat\u00e9gie d'embedding"},{"location":"experimentations/api_visualisations/#problemes","text":"Malheureusement, apr\u00e8s avoir fait plus de tests, la qualit\u00e9 des synonymes laissait \u00e0 d\u00e9sirer, principalement parce que les API ne renvoyaient pas des synonymes de qualit\u00e9 en premier lieu, probl\u00e8me que le filtrage ne suffisait pas \u00e0 r\u00e9soudre. La d\u00e9pendance \u00e0 des API est aussi probl\u00e9matique car elle n\u00e9cessite une connexion internet et suppose que les API soient fonctionnelles. Nous avons donc d\u00e9cid\u00e9 de changer de m\u00e9thode, comme pr\u00e9sent\u00e9 dans la partie suivante.","title":"Probl\u00e8mes"},{"location":"experimentations/llm/","text":"LLM Afin de r\u00e9soudre les probl\u00e8mes de la m\u00e9thode pr\u00e9c\u00e9dente, nous avons compl\u00e8tement chang\u00e9 d'approche. Nous avons d\u00e9cid\u00e9 d'utiliser un LLM traditionnel (similaire \u00e0 ChatGPT par exemple). En l'occurence, notre choix s'est port\u00e9 sur Qwen3 , car il est haut dans les leaderboards (comme on peut le voir ici ), et qu'il y a des versions compress\u00e9es, moins intelligentes, mais suffisamment l\u00e9g\u00e8res pour \u00eatre utilis\u00e9es localement. Un avantage majeur d'utiliser un LLM est sa grande flexibilit\u00e9: il suffit de modifier le prompt pour g\u00e9n\u00e9rer diff\u00e9rents types de contenus. En l'occurence, pour g\u00e9n\u00e9rer des synonymes, nous sommes arriv\u00e9s \u00e0 ce prompt gr\u00e2ce \u00e0 des tests it\u00e9ratifs rapides: In a ubiquitous language glossary named \"<nom du glossaire>\" and with the following description: <description du glossaire> The glossary currently contains the following words: <mots du glossaire> Find synonyms of the word \"<mot>\" as defined by: <d\u00e9finition du mot> Already known synonyms for the correct sense of the word: <liste des synonymes d\u00e9j\u00e0 pr\u00e9sents> Your response MUST be in the original word's language. Respond ONLY with the synonyms, separated by commas. Do not include any other text in your response. Il suffit ensuite de nettoyer la r\u00e9ponse donn\u00e9e par l'IA en appliquant ces \u00e9tapes: Suppression de certains caract\u00e8res que l'IA utilise parfois ( ' , \" , . ) Passage en minuscules de tous les mots D\u00e9duplication des mots, incluant les pluriels M\u00eame si les r\u00e9sultats ne sont pas parfaits (par exemple, l'IA g\u00e9n\u00e8re souvent des r\u00e9ponses en anglais m\u00eame lorsque le glossaire est en fran\u00e7ais), \u00e0 cause des capacit\u00e9s limit\u00e9es des petits mod\u00e8les, ils restent globalement de bonne qualit\u00e9. C'est donc cette m\u00e9thode qui a \u00e9t\u00e9 retenue pour l'application finale.","title":"LLM"},{"location":"experimentations/llm/#llm","text":"Afin de r\u00e9soudre les probl\u00e8mes de la m\u00e9thode pr\u00e9c\u00e9dente, nous avons compl\u00e8tement chang\u00e9 d'approche. Nous avons d\u00e9cid\u00e9 d'utiliser un LLM traditionnel (similaire \u00e0 ChatGPT par exemple). En l'occurence, notre choix s'est port\u00e9 sur Qwen3 , car il est haut dans les leaderboards (comme on peut le voir ici ), et qu'il y a des versions compress\u00e9es, moins intelligentes, mais suffisamment l\u00e9g\u00e8res pour \u00eatre utilis\u00e9es localement. Un avantage majeur d'utiliser un LLM est sa grande flexibilit\u00e9: il suffit de modifier le prompt pour g\u00e9n\u00e9rer diff\u00e9rents types de contenus. En l'occurence, pour g\u00e9n\u00e9rer des synonymes, nous sommes arriv\u00e9s \u00e0 ce prompt gr\u00e2ce \u00e0 des tests it\u00e9ratifs rapides: In a ubiquitous language glossary named \"<nom du glossaire>\" and with the following description: <description du glossaire> The glossary currently contains the following words: <mots du glossaire> Find synonyms of the word \"<mot>\" as defined by: <d\u00e9finition du mot> Already known synonyms for the correct sense of the word: <liste des synonymes d\u00e9j\u00e0 pr\u00e9sents> Your response MUST be in the original word's language. Respond ONLY with the synonyms, separated by commas. Do not include any other text in your response. Il suffit ensuite de nettoyer la r\u00e9ponse donn\u00e9e par l'IA en appliquant ces \u00e9tapes: Suppression de certains caract\u00e8res que l'IA utilise parfois ( ' , \" , . ) Passage en minuscules de tous les mots D\u00e9duplication des mots, incluant les pluriels M\u00eame si les r\u00e9sultats ne sont pas parfaits (par exemple, l'IA g\u00e9n\u00e8re souvent des r\u00e9ponses en anglais m\u00eame lorsque le glossaire est en fran\u00e7ais), \u00e0 cause des capacit\u00e9s limit\u00e9es des petits mod\u00e8les, ils restent globalement de bonne qualit\u00e9. C'est donc cette m\u00e9thode qui a \u00e9t\u00e9 retenue pour l'application finale.","title":"LLM"},{"location":"experimentations/premieres_experiences/","text":"Premi\u00e8res exp\u00e9riences Choix des technologies Pour commencer, il nous a fallu choisir une technologie \u00e0 utiliser. Comme nous n'arrivions pas \u00e0 faire fonctionner Word2Vec (pour des raisons techniques), nous avons initialement choisi d'utiliser un mod\u00e8le bas\u00e9 sur des transformers, facile \u00e0 lancer n'importe o\u00f9 gr\u00e2ce \u00e0 Ollama. Nous avons ensuite r\u00e9ussi \u00e0 faire fonctionner Word2Vec, et nous avons donc initialement d\u00e9cid\u00e9 de comparer les deux. Pour Word2Vec, nous avons utilis\u00e9 le corpus text8, qui contient le premier milliard de caract\u00e8res de Wikipedia. L'autre mod\u00e8le que nous avons utilis\u00e9 est MiniLM, qui est bas\u00e9 sur une architecture BERT (qui est elle-m\u00eame bas\u00e9e sur une architecture de transformers). Tests s\u00e9mantiques sur MiniLM Nous avons commenc\u00e9 par faire des tests pour voir s'il \u00e9tait possible de se baser sur la proximit\u00e9 (distance scalaire) pour trouver des relations entre les mots. Nous avons donc calcul\u00e9 la distance moyenne entre des groupes de synonymes, antonymes, mots associ\u00e9s et holonymes (relation de tout \u00e0 partie). Pour les synonymes, nous avons trouv\u00e9 un corpus de 36 000 groupes de synonymes. Nous n'avons pas trouv\u00e9 de corpus pour les autres types de mots, nous les avons donc g\u00e9n\u00e9r\u00e9s par IA. Voici les r\u00e9sultats: Synonymes Proximit\u00e9 moyenne: 0.637 Proximit\u00e9 minimale: 0.484 pour \u00e9pistaxis, saignement de nez Proximit\u00e9 maximale: 0.976 pour scintigramme, scintillogramme Antonymes Proximit\u00e9 moyenne: 0.665 Proximit\u00e9 minimale: 0.565 pour aube, cr\u00e9puscule Proximit\u00e9 maximale: 0.907 pour visible, invisible Associ\u00e9s Proximit\u00e9 moyenne: 0.640 Proximit\u00e9 minimale: 0.554 pour lion, crini\u00e8re Proximit\u00e9 maximale: 0.794 pour pluie, parapluie Holonymes Proximit\u00e9 moyenne: 0.653 Proximit\u00e9 minimale: 0.537 pour organe, corps Proximit\u00e9 maximale: 0.854 pour graine, fruit \u00c0 notre grande d\u00e9ception, tous les types de mots ont une proximit\u00e9 similaire. Apr\u00e8s r\u00e9flexion, cela para\u00eet logique, car m\u00eame si la relation entre les mots est diff\u00e9rente, ils restent proches s\u00e9mantiquement. R\u00e9cup\u00e9ration de synonymes via Word2Vec Contrairement \u00e0 MiniLM, Word2Vec permet de r\u00e9cup\u00e9rer la liste des mots qui sont proches d'un vecteur. Nous avons donc test\u00e9 de trouver des synonymes avec la m\u00e9thode suivante : on part d'un (ou plusieurs) mot(s), on les embed (c'est-\u00e0-dire les convertit en vecteur), on fait la moyenne des vecteurs obtenus, puis on r\u00e9cup\u00e8re la liste des mots les plus proches de ce vecteur. Voici les r\u00e9sultats (la proximit\u00e9 au vecteur est entre parenth\u00e8ses): Avec les mots: home, residence, house house ( 0.802 ) residence ( 0.788 ) home ( 0.749 ) palace ( 0.693 ) mansion ( 0.678 ) manor ( 0.661 ) castle ( 0.631 ) windsor ( 0.628 ) edinburgh ( 0.625 ) hotel ( 0.620 ) Avec les mots: button, zipper, latch button ( 0.989 ) buttons ( 0.829 ) hook ( 0.781 ) stick ( 0.769 ) punch ( 0.763 ) notch ( 0.762 ) pedal ( 0.754 ) tray ( 0.751 ) window ( 0.749 ) keyboard ( 0.748 ) Avec les mots: penalty, sanction, sentence penalty ( 0.861 ) sentence ( 0.849 ) defendant ( 0.712 ) felony ( 0.683 ) manslaughter ( 0.669 ) procedure ( 0.666 ) punishment ( 0.652 ) offence ( 0.634 ) conviction ( 0.634 ) wrongful ( 0.628 ) Avec les mots: ruby, emerald, sapphire sapphire ( 0.856 ) ruby ( 0.855 ) microcebus ( 0.836 ) plum ( 0.829 ) moth ( 0.825 ) bean ( 0.823 ) ginger ( 0.820 ) cabbage ( 0.819 ) emerald ( 0.817 ) marmoset ( 0.805 ) Comme on peut le voir, la qualit\u00e9 des mots est plut\u00f4t mauvaise, et les scores ne permettent pas de filtrer les meilleurs mots. En plus de cela, Word2Vec ne supporte pas le contexte (c'est-\u00e0-dire qu'on ne peut embedder qu'un seul mot \u00e0 la fois). M\u00eame si nous avons simul\u00e9 du contexte en faisant la moyenne de plusieurs mots, c'est tout de m\u00eame moins qualitatif qu'un mod\u00e8le qui permet d'utiliser du contexte. Au vu du manque d'efficacit\u00e9 de cette m\u00e9thode, nous avons d\u00e9cid\u00e9 de changer de m\u00e9thode pour d\u00e9terminer les synonymes d'un mot.","title":"Premi\u00e8res exp\u00e9riences"},{"location":"experimentations/premieres_experiences/#premieres-experiences","text":"","title":"Premi\u00e8res exp\u00e9riences"},{"location":"experimentations/premieres_experiences/#choix-des-technologies","text":"Pour commencer, il nous a fallu choisir une technologie \u00e0 utiliser. Comme nous n'arrivions pas \u00e0 faire fonctionner Word2Vec (pour des raisons techniques), nous avons initialement choisi d'utiliser un mod\u00e8le bas\u00e9 sur des transformers, facile \u00e0 lancer n'importe o\u00f9 gr\u00e2ce \u00e0 Ollama. Nous avons ensuite r\u00e9ussi \u00e0 faire fonctionner Word2Vec, et nous avons donc initialement d\u00e9cid\u00e9 de comparer les deux. Pour Word2Vec, nous avons utilis\u00e9 le corpus text8, qui contient le premier milliard de caract\u00e8res de Wikipedia. L'autre mod\u00e8le que nous avons utilis\u00e9 est MiniLM, qui est bas\u00e9 sur une architecture BERT (qui est elle-m\u00eame bas\u00e9e sur une architecture de transformers).","title":"Choix des technologies"},{"location":"experimentations/premieres_experiences/#tests-semantiques-sur-minilm","text":"Nous avons commenc\u00e9 par faire des tests pour voir s'il \u00e9tait possible de se baser sur la proximit\u00e9 (distance scalaire) pour trouver des relations entre les mots. Nous avons donc calcul\u00e9 la distance moyenne entre des groupes de synonymes, antonymes, mots associ\u00e9s et holonymes (relation de tout \u00e0 partie). Pour les synonymes, nous avons trouv\u00e9 un corpus de 36 000 groupes de synonymes. Nous n'avons pas trouv\u00e9 de corpus pour les autres types de mots, nous les avons donc g\u00e9n\u00e9r\u00e9s par IA. Voici les r\u00e9sultats: Synonymes Proximit\u00e9 moyenne: 0.637 Proximit\u00e9 minimale: 0.484 pour \u00e9pistaxis, saignement de nez Proximit\u00e9 maximale: 0.976 pour scintigramme, scintillogramme Antonymes Proximit\u00e9 moyenne: 0.665 Proximit\u00e9 minimale: 0.565 pour aube, cr\u00e9puscule Proximit\u00e9 maximale: 0.907 pour visible, invisible Associ\u00e9s Proximit\u00e9 moyenne: 0.640 Proximit\u00e9 minimale: 0.554 pour lion, crini\u00e8re Proximit\u00e9 maximale: 0.794 pour pluie, parapluie Holonymes Proximit\u00e9 moyenne: 0.653 Proximit\u00e9 minimale: 0.537 pour organe, corps Proximit\u00e9 maximale: 0.854 pour graine, fruit \u00c0 notre grande d\u00e9ception, tous les types de mots ont une proximit\u00e9 similaire. Apr\u00e8s r\u00e9flexion, cela para\u00eet logique, car m\u00eame si la relation entre les mots est diff\u00e9rente, ils restent proches s\u00e9mantiquement.","title":"Tests s\u00e9mantiques sur MiniLM"},{"location":"experimentations/premieres_experiences/#recuperation-de-synonymes-via-word2vec","text":"Contrairement \u00e0 MiniLM, Word2Vec permet de r\u00e9cup\u00e9rer la liste des mots qui sont proches d'un vecteur. Nous avons donc test\u00e9 de trouver des synonymes avec la m\u00e9thode suivante : on part d'un (ou plusieurs) mot(s), on les embed (c'est-\u00e0-dire les convertit en vecteur), on fait la moyenne des vecteurs obtenus, puis on r\u00e9cup\u00e8re la liste des mots les plus proches de ce vecteur. Voici les r\u00e9sultats (la proximit\u00e9 au vecteur est entre parenth\u00e8ses): Avec les mots: home, residence, house house ( 0.802 ) residence ( 0.788 ) home ( 0.749 ) palace ( 0.693 ) mansion ( 0.678 ) manor ( 0.661 ) castle ( 0.631 ) windsor ( 0.628 ) edinburgh ( 0.625 ) hotel ( 0.620 ) Avec les mots: button, zipper, latch button ( 0.989 ) buttons ( 0.829 ) hook ( 0.781 ) stick ( 0.769 ) punch ( 0.763 ) notch ( 0.762 ) pedal ( 0.754 ) tray ( 0.751 ) window ( 0.749 ) keyboard ( 0.748 ) Avec les mots: penalty, sanction, sentence penalty ( 0.861 ) sentence ( 0.849 ) defendant ( 0.712 ) felony ( 0.683 ) manslaughter ( 0.669 ) procedure ( 0.666 ) punishment ( 0.652 ) offence ( 0.634 ) conviction ( 0.634 ) wrongful ( 0.628 ) Avec les mots: ruby, emerald, sapphire sapphire ( 0.856 ) ruby ( 0.855 ) microcebus ( 0.836 ) plum ( 0.829 ) moth ( 0.825 ) bean ( 0.823 ) ginger ( 0.820 ) cabbage ( 0.819 ) emerald ( 0.817 ) marmoset ( 0.805 ) Comme on peut le voir, la qualit\u00e9 des mots est plut\u00f4t mauvaise, et les scores ne permettent pas de filtrer les meilleurs mots. En plus de cela, Word2Vec ne supporte pas le contexte (c'est-\u00e0-dire qu'on ne peut embedder qu'un seul mot \u00e0 la fois). M\u00eame si nous avons simul\u00e9 du contexte en faisant la moyenne de plusieurs mots, c'est tout de m\u00eame moins qualitatif qu'un mod\u00e8le qui permet d'utiliser du contexte. Au vu du manque d'efficacit\u00e9 de cette m\u00e9thode, nous avons d\u00e9cid\u00e9 de changer de m\u00e9thode pour d\u00e9terminer les synonymes d'un mot.","title":"R\u00e9cup\u00e9ration de synonymes via Word2Vec"}]}