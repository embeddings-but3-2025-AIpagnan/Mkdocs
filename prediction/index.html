<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Prediction-Based Embeddings - embedding</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Prediction-Based Embeddings";
        var mkdocs_page_input_path = "prediction.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> embedding
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Recherches théoriques</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../principes/">Principes de l'embedding</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Les différents types d'embedding</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../frequency/">Frequency-Based Embeddings</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="#">Prediction-Based Embeddings</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#exemples">Exemples :</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#word2vec">Word2Vec :</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#avantages">Avantages :</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#inconvenients">Inconvénients :</a>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../contextualized/">Contextualized Word Embeddings</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../creation/">Création des embeddings</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Expérimentations</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../demarches/">Démarches</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../resultats/">Résultats</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Application</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >Recherches</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../contexte_technos/">Introduction</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../front-end_technos/">Front-end</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../integration-js_technos/">Intégration JS</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../conclusion_technos/">Conclusion</a>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">embedding</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Recherches théoriques</li>
          <li class="breadcrumb-item">Les différents types d'embedding</li>
      <li class="breadcrumb-item active">Prediction-Based Embeddings</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="embeddings-predictifs-prediction-based-embeddings">Embeddings prédictifs (Prediction-Based Embeddings)</h1>
<p>Ces modèles apprennent les vecteurs en prévoyant un mot à partir de son contexte ou l’inverse.</p>
<p>Utilisent des réseaux de neurones simples pour créer des représentations distribuées.</p>
<h2 id="exemples">Exemples :</h2>
<h3 id="word2vec">Word2Vec :</h3>
<ul>
<li>
<p><code>Skip-gram</code> : prédit les mots du contexte à partir du mot cible.</p>
</li>
<li>
<p><code>CBOW</code> (Continuous Bag of Words) : prédit le mot cible à partir du contexte.</p>
</li>
<li>
<p><code>GloVe</code> : combine approche de cooccurrence et apprentissage prédictif ; s’appuie sur la probabilité relative de cooccurrence entre mots.</p>
</li>
</ul>
<h2 id="avantages">Avantages :</h2>
<p>efficaces, rapides à entraîner, bonnes performances sur les similarités sémantiques.</p>
<h2 id="inconvenients">Inconvénients :</h2>
<p>un seul vecteur par mot, pas de prise en compte du contexte (un mot a toujours le même vecteur, quel que soit son sens dans la phrase).</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../frequency/" class="btn btn-neutral float-left" title="Frequency-Based Embeddings"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../contextualized/" class="btn btn-neutral float-right" title="Contextualized Word Embeddings">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../frequency/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../contextualized/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
